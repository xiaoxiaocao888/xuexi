**robots.txt协议**
君子协议。规定了网站中哪些数据可以被爬虫爬取哪些数据不可以被爬取

```python
from urllib.request import urlopen
url="http://www.baidu.com"
resp=urlopen(url)
with open("mybaidu.html",mode="w") as f:
    f.write(resp.read().decode("utf-8"))
print("over!")
```
从路由里面的请求库里面引入urlopen，urlopen(url)就相当于一个浏览器打开一个网址，resp就是响应的。

**服务器渲染** ：在服务器那边直接把数据和html整合在一起，统一返回给浏览器，在页面源代码中可以看到数据
**客户端渲染** ：第一次请求只要一个html骨架，第二次请求拿到数据，进行数据展示。在页面源代码中看不到数据

##### 请求头中最常见的一些重要内容
1.User-agent：请求载体的身份标识（用啥发送的请求）
2.Referer:防盗链（这次请求是从哪个页面来的？反爬会用到）
3.cookie:本地字符串数据信息（用户登录信息，反爬的token)

##### 响应头中一些重要的内容
1.cookie：本地字符串数据信息（用户登录信息，反爬的token)

安装requests
```
pip install requests
```

##### 安装使用国内源
1.使用百度的清华源
![[Pasted image 20250309103815.png]]
然后赋值这个，把后面的some-package改为你要下载的东西，如requests
![[Pasted image 20250309103841.png]]