安装
```
pip install bs4
```
**直接通过get就可以拿到属性的值**
**find那些找的是标签**
eg：
```python
#1.拿到页面源代码
#2.使用bs4进行解析，拿到数据
import requests
from bs4 import BeautifulSoup
import csv
url="http://www.xinfadi.com.cn/marketanalysis/0/list/1.shtml"
resp=requests.get(url)
f=open("菜价.csv",mode="w")
csvwriter=csv.writer(f)
#解析数据
#1.把页面源代码交给BeautifulSoup进行处理，生成bs对象
page=BeautifulSoup(resp.text,"html.parser")#指定html解析器，不然会有警告，不知道数据是什么类型
#2.从bs对象中查找数据
#table=page.find("table",class_="hq_table")#避免python关键字
table=page.find("table",attrs={"class":"hq_table"})#属性：值
#拿到所有数据行
trs=table.find_all("tr")[1:]
for tr in trs:
    tds=tr.find_all("td")
    name=tds[0].text
    low=tds[1].text
    avg=tds[2].text
    high=tds[3].text
    gui=tds[4].text
    kind=tds[5].text
    date=tds[6].text
    csvwriter.writerow([name,low,avg,high,gui,kind,date])
f.close()
resp.close()
print("over")
```

##### eg 下载图片
```python
#1.拿到主页面的源代码，然后提取子页面的链接地址，href
#2.通过href拿到子页面的你日头，从子页面中找到图片的下载地址img->src
#3.下载图片
import requests
from bs4 import BeautifulSoup
import time
url="https://www.umei.cc/weimeitupian/keaitupian/"
domain="https://www.umei.cc"
resp=requests.get(url)
resp.encoding='utf-8' #处理乱码
#print(resp.text)
#把源代码交给bs
main_page=BeautifulSoup(resp.text,"html.parser")
alist=main_page.find_all("a",class_="img_album_btn")
#print(alist)
for a in alist:
    href=domain+a.get('href')#直接通过get就可以拿到属性的值
    #print(href)
    #拿到子页面的源代码
    child_page_resp=requests.get(href)
    child_page_resp.encoding='utf-8'
    child_page_text=child_page_resp.text
    #从子页面中拿到图片的下载路径
    child_page=BeautifulSoup(child_page_text,"html.parser")
    p=child_page.find("div",class_="big-pic")
    img=p.find("img")
    src=img.get("src")
    #下载图片
    img_resp=requests.get(src)
    img_name=src.split("/")[-1]#拿到url中最后一个/以后的内容
    with open("img/"+img_name,mode="wb") as f:
        f.write(img_resp.content)#这里拿到的是字节
        f.close()
        print("over"+img_name)
        break
resp.close()
```