1.注册，获取API key
```
https://www.deepseek.com/
```
2.在模型练习文件夹目录下新建.env文件，要是看不到文件的后缀，我们可以点击查看，勾选上扩展名，就可以。
```
DEEPSEEK_API_KEY="xxx" #替换成上面获取的key
DEEPSEEK_API_BASE="https://api.deepseek.com"
```
3.下载openai。ctrl+shift+P输入python:select Inspector选择miniconda的解释器
```
pip install openai -i https://pypi.tuna.tsinghua.edu.cn/simple
```
模型调用风格和OpenAI完全一致，deepseek-chat模型支持Function calling、提示词缓存、Json Output等Agent开发关键功能
deepseek-chat模型是DeepSeek-V3，通过指定即可调用
```
model='deepseek-chat'
```
4.简单的来个单次响应。要充值才能有响应
```python
from openai import OpenAI
from dotenv import load_dotenv
import os
load_dotenv(override=True)
DS_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DS_BASE_URL = os.getenv("DEEPSEEK_API_BASE")
client = OpenAI(api_key=DS_API_KEY, base_url=DS_BASE_URL)
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=[
        {"role": "user", "content": "Hello"},
    ]
)
print(response.choices[0].message.content)#输出生成的响应内容
print(response)
```
![[Pasted image 20250601155319.png]]
response打印的reasoning_content字段中的内容则是DeepSeek-R1-0528模型在回答问题之前生成的思考过程信息

##### DeepSeek-R1-0528是推理模型，参数介绍
**核心参数messages**
用于定义聊天上下文。包括用户的输入、系统的指令、助手的回复(assistant）等。
`system message`:用于设置系统消息，通常由开发者设定，以指导模型如何进行对话。`content`系统消息的内容。`role`:system 表面是系统发出的消息。`name`可选，提供系统消息发送者的名称
```
system_message={
"role":"system",
"content":"你是一位助人为乐的助手"
}
user_message = {"role": "user","content": "请帮我介绍下什么是机器学习。"}
messages=[ system_message, user_message ]
```
**必填参数model** 指定使用哪个模型

##### 借助Messages参数构建多轮对话机器人
下载ipython
```
pip install ipython -i https://pypi.tuna.tsinghua.edu.cn/simple
```
执行发现display函数是只能在jupyter notebook环境进行渲染
![[Pasted image 20250601161501.png]]
```python
import re
import os
from IPython.display import display, Code, Markdown
load_dotenv(override=True)
DS_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DS_BASE_URL = os.getenv("DEEPSEEK_API_BASE")
client = OpenAI(api_key=DS_API_KEY, base_url=DS_BASE_URL)
def chat_with_DeepSeek(client, messages):
    """
    使用 DeepSeek 模型进行多轮对话。
    参数:
      client: 实例化的 OpenAI 客户端。
      messages (list): 对话上下文消息列表。
    返回:
      str: 模型生成的回复文本。
    """
    response = client.chat.completions.create(
        model="deepseek-reasoner",      # 注意：这里加载 DeepSeek R1 模型
        messages=messages
    )
    return response.choices[0].message.content

def multi_round_chat(client):
    """
    多轮对话机器人示例函数，支持纯文本对话（不处理 URL）。
    用户输入 'exit' 时退出对话。
    """
    # 初始化消息列表，加入系统消息
    messages = [{"role": "system", "content": "你是一名助人为乐的助手。"}]
    
    while True:
        user_input = input("User: ").strip()
        if user_input.lower() == 'exit':
            print("对话结束。")
            break
        
        # 直接构造用户消息
        messages.append({"role": "user", "content": user_input})
        
        # 调用 DeepSeek 模型获取回复
        assistant_reply = chat_with_DeepSeek(client, messages)
        # display(Markdown(f"Assistant: {assistant_reply}"))           # 命令行友好输出 
        print("\n" + "=" * 60) 
        print(f"Assistant: {assistant_reply}") 
        print("=" * 60 + "\n")
        # 添加助手回复到消息列表中
        messages.append({"role": "assistant", "content": assistant_reply})
```
