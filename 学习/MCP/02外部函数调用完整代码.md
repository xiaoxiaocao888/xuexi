运行结果
![[Pasted image 20250506190715.png]]
能调用外部工具，是大模型进化为智能体Agent的关键，如果不能使用外部工具，大模型就只能是个简单的聊天机器人，甚至连查询天气都做不到。对于大模型来说，Function calling的本质，是当模型在特殊情况下的一种特殊响应形式。而要拥有Function calling功能，其实是需要在模型指令微调阶段进行训练的
###### 调用外部函数要发起两次请求
**第一次请求**：
让模型判断是否需要调用工具，并生成结构化参数。(选择外部函数，确定参数)
此时输入 ，
```Python
response.choices[0].message.content  # v3模型显示为空，r1模型:我将调用函数查询北京的天气情况
response.choices[0].finish_reason    # tool_calls 正常要是结束对话，就是stop
response.choices[0].message.tool_calls # 此时模型tool_calls的全部信息都保存在message.tool_calls中
```
外部函数执行(两次请求之间)
外部函数的计算过程仍然是在本地执行，即Chat模型并不会将代码读取到服务器上再进行在线计算，因此接下来我们需要根据模型返回的函数和函数参数，在本地完成函数计算，然后再将计算过程和结果保存为message并追加到messages后面，并第二次调用Chat模型分析函数的计算结果，并最终根据函数计算结果输出用户问题的答案。
**第二次请求**：
将外部函数返回的原始数据转化为用户友好的自然语言回答
```python
import requests
import os
import json
from openai import OpenAI
open_weather_key=os.getenv("OPENWEATHER_API_KEY")
def get_weather(loc):
    #1.构建请求
    url="https://api.openweathermap.org/data/2.5/weather"
    #2.设置查询参数
    params={
      "q":loc,#城市名要英文
      "appid":open_weather_key,
      "units":"metric", #使用摄氏度
      "lang":"zh_cn"
    }
    #3.发送get请求
    response=requests.get(url,params=params)
    #4.解析响应
    data=response.json()
    return json.dumps(data)
def run_conv(messages,
             tools=None,
             functions_list=None,
             model="krith/qwen2.5-7b-instruct:IQ4_XS"):
    """
    能够自动执行外部函数调用的Chat对话模型
    :param messages:必要参数，输入到Chat模型的messages参数对象
    :param tools:可选参数，默认为None，可以设置为包含全部外部函数的列表对象
    :param model:Chat模型，可选参数，默认模型为gpt-3.5-turbo-0613
    :return:Chat模型输出结果
    """
    user_messages=messages
    #如果没有外部函数库，则执行普通的对话任务
    if tools==None:
        response = client.chat.completions.create(
           model="deepseek-r1:70b",
           messages=user_messages
        )
        final_response=response.choices[0].message.content
    #若存在外部函数库，则需要灵活选取外部函数并进行回答
    else:
        #创建外部函数库字典 name为key，func为值
        available_funtions={func.__name__:func for func in functions_list}
        #创建包含用户问题的message
        messages=user_messages
        #first response
        response=client.chat.completions.create(
            model=model,
            messages=user_messages,
            tools=tools,
        )
        response_message=response.choices[0].message
        #获取函数名
        function_name=response_message.tool_calls[0].function.name
        #获取函数对象
        function_to_call=available_funtions[function_name]
        #获取函数参数
        function_args=json.loads(response_message.tool_calls[0].function.arguments)
        #将函数参数输入到函数中，获取函数计算结果
        function_response=function_to_call(**function_args)
        #messages中拼接first response消息
        user_messages.append(response_message.model_dump())
        #将messages中拼接外部函数输出结果
        user_messages.append(
            {
                "role":"tool",
                "content":function_response,
                "tool_call_id":response_message.tool_calls[0].id
            }
        )
        #第二次调用模型
        second_response=client.chat.completions.create(
            model=model,
            messages=user_messages
        )
        #获取最终结果
        final_response=second_response.choices[0].message.content
    return final_response
get_weather_function={
    'name':'get_weather',
    'description':'查询即时天气函数，根据输入的城市名称，查询对应城市的实时天气',
    'parameters':{
        'type':'object',
        'properties':{
            'loc':{
                'description':"城市名称，注意，中国的城市需要用对应的城市的英文表示",
                "type":"string"
            }
        },
        'required':['loc']
    }
}
available_funtions={
    "get_weather":get_weather,
}
tools=[
    {
        "type":"function",
        "function":get_weather_function
    }
]
client = OpenAI(
    base_url="http://36.212.4.98:18001/v1",  # 注意/v1后缀
    #base_url="http://localhost:11434/v1",
    api_key="ollama"  # Ollama不需要密钥，但某些库要求必填
)
messages=[{"role":"user","content":"请问北京今天天气如何？"}]
print(run_conv([{"role":"user","content":"请问什么是机器学习？"}]))
print(run_conv(messages=messages,tools=tools,functions_list=[get_weather]))
```