æˆ‘ä»¬åˆ›å»ºæ–°çš„æ–‡ä»¶connect.py(è§†é¢‘æ˜¯è¯´ä¿®æ”¹client.pyï¼Œæˆ‘æ˜¯åˆ›å»ºæ–°çš„)
å¼•å…¥stdio_clientæ˜¯ä¸ºäº†è®©client.pyå’Œserver.pyåŒæ—¶è¿è¡Œï¼Œå®æ—¶é€šä¿¡
è¿è¡Œ
```
uv run connect.py server.py
```
![[Pasted image 20250511173750.png]]
å¯¼å…¥ä¾èµ–
```python
import asyncio
import os
import json
from typing import Optional
from contextlib import AsyncExitStack

from openai import OpenAI  
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿ API Key å—åˆ°ä¿æŠ¤
load_dotenv()
class MCPClient:
```
##### åˆ›å»ºç±»MCPClientçš„å‡½æ•°
###### åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
ä¸»è¦ä½œç”¨æ˜¯ä¸ºå®¢æˆ·ç«¯å»ºç«‹ä¸ OpenAI æœåŠ¡å’Œ MCP æœåŠ¡å™¨é€šä¿¡çš„åŸºç¡€è®¾æ–½ã€‚
```python
def __init__(self):
    """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
    # åˆå§‹åŒ–å¼‚æ­¥èµ„æºç®¡ç†æ ˆï¼ˆç”¨äºç®¡ç†è¿æ¥æ± ã€ä¼šè¯ç­‰ï¼‰
    self.exit_stack = AsyncExitStack()  
    
    # ä»ç¯å¢ƒå˜é‡åŠ è½½ OpenAI é…ç½®
    self.openai_api_key = os.getenv("OPENAI_API_KEY")  # API å¯†é’¥
    self.base_url = os.getenv("BASE_URL")             # OpenAI æœåŠ¡åœ°å€ï¼ˆå¯èƒ½ä¸ºä»£ç†åœ°å€ï¼‰
    self.model = os.getenv("MODEL")                   # ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚ gpt-3.5-turboï¼‰
    
    # å¼ºåˆ¶æ ¡éªŒ OpenAI API Key æ˜¯å¦å­˜åœ¨
    if not self.openai_api_key:
        raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")
    
    # åˆ›å»º OpenAI å®˜æ–¹å®¢æˆ·ç«¯å®ä¾‹
    self.client = OpenAI(
        api_key=self.openai_api_key, 
        base_url=self.base_url  # å…¼å®¹å®˜æ–¹APIæˆ–ç¬¬ä¸‰æ–¹ä»£ç†
    )
    
    # åˆå§‹åŒ– MCP ä¼šè¯å¯¹è±¡ï¼ˆç¨åé€šè¿‡ connect_to_server æ–¹æ³•å¡«å……ï¼‰
    self.session: Optional[ClientSession] = None  
```
###### è¿æ¥åˆ° MCP æœåŠ¡å™¨å¹¶è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
`server_script_path`Â å‚æ•°æ˜¯ æœåŠ¡å™¨è„šæœ¬è·¯å¾„
åˆ›å»ºÂ `StdioServerParameters`Â å¯¹è±¡é…ç½®æœåŠ¡å™¨å¯åŠ¨å‚æ•°
    - `command`ï¼šæ‰§è¡Œå‘½ä»¤
    - `args`ï¼šå‘½ä»¤å‚æ•°ï¼ˆè„šæœ¬è·¯å¾„ï¼‰
    - `env`ï¼šç¯å¢ƒå˜é‡ï¼ˆæ­¤å¤„ä¸º Noneï¼Œä½¿ç”¨é»˜è®¤ç¯å¢ƒï¼‰
**å¯åŠ¨æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡é€šé“**
- `stdio_client(server_params)`ï¼šé€šè¿‡æ ‡å‡†è¾“å…¥è¾“å‡ºï¼ˆSTDIOï¼‰å¯åŠ¨æœåŠ¡å™¨è¿›ç¨‹å¹¶å»ºç«‹å®¢æˆ·ç«¯è¿æ¥
- `exit_stack.enter_async_context()`ï¼šå°†èµ„æºåŠ å…¥å¼‚æ­¥èµ„æºç®¡ç†æ ˆï¼Œç¡®ä¿è‡ªåŠ¨æ¸…ç†
- `ClientSession`ï¼šåˆ›å»ºå®¢æˆ·ç«¯ä¼šè¯å¯¹è±¡ï¼Œç”¨äºä¸æœåŠ¡å™¨é€šä¿¡
     - `stdio_transport`Â æ˜¯Â `stdio_client(server_params)`Â è¿”å›çš„å¯¹è±¡ï¼Œå®ƒå®é™…ä¸Šæ˜¯ä¸€ä¸ª**äºŒå…ƒå…ƒç»„ï¼ˆTupleï¼‰**ï¼ŒåŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼š
        - ç¬¬ä¸€ä¸ªå…ƒç´ ï¼šæ ‡å‡†è¾“å…¥è¾“å‡ºæµå¯¹è±¡ï¼ˆé€šå¸¸ç”¨äºæ¥æ”¶æ•°æ®ï¼‰
        - ç¬¬äºŒä¸ªå…ƒç´ ï¼šå†™å…¥å‡½æ•°ï¼ˆé€šå¸¸ç”¨äºå‘é€æ•°æ®ï¼‰ï¼Œæ‰€ä»¥æ˜¯å¯¹åº”çš„èµ‹å€¼ã€‚
- `session.initialize()`ï¼šåˆå§‹åŒ–å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨çš„ä¼šè¯
- `session.list_tools()`ï¼šå‘MCPæœåŠ¡å™¨è¯·æ±‚å¯ç”¨å·¥å…·åˆ—è¡¨ï¼Œå¤§æ¦‚æ˜¯
```python
 tools=[
        Tool(name="ç¿»è¯‘", description="å°†æ–‡æœ¬ç¿»è¯‘æˆæŒ‡å®šè¯­è¨€"),
        Tool(name="è®¡ç®—", description="æ‰§è¡Œæ•°å­¦è®¡ç®—"),
        # ...
    ]
```

```python
async def connect_to_server(self, server_script_path: str):
Â  Â  Â  Â  """è¿æ¥åˆ° MCP æœåŠ¡å™¨å¹¶åˆ—å‡ºå¯ç”¨å·¥å…·"""
Â  Â  Â  Â  is_python = server_script_path.endswith('.py')
Â  Â  Â  Â  is_js = server_script_path.endswith('.js')
Â  Â  Â  Â  if not (is_python or is_js):
Â  Â  Â  Â  Â  Â  raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ .py æˆ– .js æ–‡ä»¶")
Â  Â  Â  Â  command = "python" if is_python else "node"
Â  Â  Â  Â  server_params = StdioServerParameters(
Â  Â  Â  Â  Â  Â  command=command,
Â  Â  Â  Â  Â  Â  args=[server_script_path],
Â  Â  Â  Â  Â  Â  env=None
Â  Â  Â  Â  )
Â  Â  Â  Â  # å¯åŠ¨ MCP æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
Â  Â  Â  Â  stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
Â  Â  Â  Â  self.stdio, self.write = stdio_transport
Â  Â  Â  Â  self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
Â  Â  Â  Â  await self.session.initialize()
Â  Â  Â  Â  # åˆ—å‡º MCP æœåŠ¡å™¨ä¸Šçš„å·¥å…·
Â  Â  Â  Â  response = await self.session.list_tools()
Â  Â  Â  Â  tools = response.tools
Â  Â  Â  Â  print("\nå·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·:", [tool.name for tool in tools])
```
###### å¤„ç†ç”¨æˆ·å…³äºåŸå¸‚ä¿¡æ¯çš„æŸ¥è¯¢ï¼Œæ™ºèƒ½è°ƒç”¨å¤–éƒ¨å·¥å…·è·å–æ•°æ®ï¼Œå¹¶ç”Ÿæˆæœ€ç»ˆå›ç­”
.argumentsæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«äº†æ¨¡å‹ç”Ÿæˆçš„å·¥å…·å‚æ•°ï¼Œå¦‚
```python
tool_args = {"city": "åŒ—äº¬", "date": "2023-05-11"}
```
content.message.model_dump()å°† OpenAI æ¨¡å‹è¿”å›çš„Â `content.message`Â å¯¹è±¡ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ª Pydantic æ¨¡å‹å®ä¾‹ï¼‰è½¬æ¢ä¸ºå­—å…¸
```python
async def process_query(self, city: str) -> str:
Â  Â  Â  Â  """ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†æŸ¥è¯¢å¹¶è°ƒç”¨å¯ç”¨çš„ MCP å·¥å…· (Function Calling)"""
Â  Â  Â  Â  messages = [{"role": "user", "content": f"å…³äº{city}çš„ä¿¡æ¯ï¼Œè¯·å§‹ç»ˆç”¨ä¸­æ–‡åŸå¸‚åç§°"}]
Â  Â  Â  Â  response=await self.session.list_tools()
Â  Â  Â  Â  available_tools = [{
Â  Â  Â  Â  Â  Â  "type": "function",
Â  Â  Â  Â  Â  Â  "function": {
Â  Â  Â  Â  Â  Â  Â  Â  "name": tool.name,
Â  Â  Â  Â  Â  Â  Â  Â  "description": tool.description,
Â  Â  Â  Â  Â  Â  Â  Â  "input_schema": tool.inputSchema
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } for tool in response.tools]
Â  Â  Â  Â  # print(available_tools)
Â  Â  Â  Â  # ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
Â  Â  Â  Â  response = self.client.chat.completions.create(
Â  Â  Â  Â  Â  Â  model=self.model, Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â  messages=messages,
Â  Â  Â  Â  Â  Â  tools=available_tools Â  Â 
Â  Â  Â  Â  )
Â  Â  Â  Â  # å¤„ç†è¿”å›çš„å†…å®¹
Â  Â  Â  Â  content = response.choices[0]
Â  Â  Â  Â  if content.finish_reason == "tool_calls":
Â  Â  Â  Â  Â  Â  # å¦‚æœæ˜¯éœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå°±è§£æå·¥å…·
Â  Â  Â  Â  Â  Â  tool_call = content.message.tool_calls[0]
Â  Â  Â  Â  Â  Â  tool_name = tool_call.function.name
Â  Â  Â  Â  Â  Â  tool_args = json.loads(tool_call.function.arguments)
Â  Â  Â  Â  Â  Â  # æ‰§è¡Œå·¥å…·
Â  Â  Â  Â  Â  Â  result = await self.session.call_tool(tool_name, tool_args)
Â  Â  Â  Â  Â  Â  print(f"\n\n[Calling tool {tool_name} with args {tool_args}]\n\n")
Â  Â  Â  Â  Â  Â  # å°†æ¨¡å‹è¿”å›çš„è°ƒç”¨å“ªä¸ªå·¥å…·æ•°æ®å’Œå·¥å…·æ‰§è¡Œå®Œæˆåçš„æ•°æ®éƒ½å­˜å…¥messagesä¸­
Â  Â  Â  Â  Â  Â  messages.append(content.message.model_dump())
Â  Â  Â  Â  Â  Â  messages.append({
Â  Â  Â  Â  Â  Â  Â  Â  "role": "tool",
Â  Â  Â  Â  Â  Â  Â  Â  "content": result.content[0].text,
Â  Â  Â  Â  Â  Â  Â  Â  "tool_call_id": tool_call.id,
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œå°†ä¸Šé¢çš„ç»“æœå†è¿”å›ç»™å¤§æ¨¡å‹ç”¨äºç”Ÿäº§æœ€ç»ˆçš„ç»“æœ
Â  Â  Â  Â  Â  Â  response = self.client.chat.completions.create(
Â  Â  Â  Â  Â  Â  Â  Â  model=self.model,
Â  Â  Â  Â  Â  Â  Â  Â  messages=messages,
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  return response.choices[0].message.content
Â  Â  Â  Â  return content.message.content
```

###### äº¤äº’å¼èŠå¤©å¾ªç¯
```python
async def chat_loop(self):
Â  Â  Â  Â  """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
Â  Â  Â  Â  print("\nğŸ¤– MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
Â  Â  Â  Â  while True:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  city = input("\nä½ : ").strip()
Â  Â  Â  Â  Â  Â  Â  Â  if city.lower() == 'quit':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  Â  Â  Â  # å¤„ç†æŸ¥è¯¢ï¼Œæ˜¾ç¤ºç»“æœ
Â  Â  Â  Â  Â  Â  Â  Â  response = await self.process_query(city) Â # å‘é€ç”¨æˆ·è¾“å…¥åˆ° OpenAI API
Â  Â  Â  Â  Â  Â  Â  Â  print(f"\nğŸ¤– OpenAI: {response}")
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")
```
###### æ¸…ç†èµ„æºï¼ŒMCPClientç±»åˆ›å»ºå°±åˆ°è¿™é‡Œäº†
```python
async def cleanup(self):
Â  Â  Â  Â  """æ¸…ç†èµ„æº"""
Â  Â  Â  Â  await self.exit_stack.aclose()
```
ä¸»ä½“
```python
async def main():
Â  Â  if len(sys.argv) < 2:
Â  Â  Â  Â  print("Usage: python client.py <path_to_server_script>")
Â  Â  Â  Â  sys.exit(1)
Â  Â  client = MCPClient()
Â  Â  try:
Â  Â  Â  Â  await client.connect_to_server(sys.argv[1])
Â  Â  Â  Â  await client.chat_loop()
Â  Â  finally:
Â  Â  Â  Â  await client.cleanup()
if __name__ == "__main__":
Â  Â  import sys
Â  Â  asyncio.run(main())
```