新建bert_createdata.py文件.数据保存成hugging face格式
```python
dataset = [
    ("这款手机性价比超高，拍照效果堪比专业相机，续航也很给力", 1),
    ("餐厅服务太差了，等位一小时不说，上菜还特别慢", 0),...省略了]
from datasets import Dataset
import os
# 将列表转换为 datasets.Dataset 对象，需整理成字典形式，键对应特征名
data_dict = {
    "text": [item[0] for item in dataset],
    "label": [item[1] for item in dataset]
}
hf_dataset = Dataset.from_dict(data_dict)
# 定义要保存的文件夹名称，按照你的需求设为 vail
save_folder = "vail"
# 如果文件夹不存在则创建
if not os.path.exists(save_folder):
    os.makedirs(save_folder)
# 保存数据集到指定文件夹，这会生成 Hugging Face 数据集默认的文件结构（包含.arrow 等文件）
hf_dataset.save_to_disk(save_folder)
```
即生成的vail文件夹里面包含的文件有
![[Pasted image 20250613174623.png]]

新建bert_vail.py文件，来验证准确率
使用容易分辨的数据集，准确率很高
![[Pasted image 20250613174830.png]]
使用有点难分辨的数据集，准确率也还可以
![[Pasted image 20250613174910.png]]
```python
import torch
from bert_data1 import Mydataset
from torch.utils.data import DataLoader
from bert_net1 import Model
from transformers import BertTokenizer,AdamW
from torch.utils.data import Dataset
from datasets import load_from_disk
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
EPOCH = 100
token = BertTokenizer.from_pretrained("/data/home/zengxiangxi/xuexi/bertlianxi/huggingface/model_cache/models--bert-base-chinese/snapshots/c30a6ed22ab4564dc1e3b2ecbf6e766b0611a33f")
def collate_fn(data):
    sentes = [i["text"] for i in data]  # 假设数据集里文本的键是 "text"，标签是 "label"，根据实际情况调整
    label = [i["label"] for i in data]
    # 编码
    data = token.batch_encode_plus(
        batch_text_or_text_pairs=sentes,
        truncation=True,
        padding="max_length",
        max_length=350,
        return_tensors="pt",
        return_length=True,
    )
    input_ids = data["input_ids"]
    attention_mask = data["attention_mask"]
    token_type_ids = data["token_type_ids"]
    labels = torch.LongTensor(label)

    return input_ids, attention_mask, token_type_ids, labels
#创建数据集
vail_dataset = load_from_disk(r"/data/home/zengxiangxi/xuexi/bertlianxi/vail1")
#创建DataLoader
vail_laoder = DataLoader(
    dataset=vail_dataset,
    batch_size=32,
    shuffle=True,
    drop_last=True,
    collate_fn=collate_fn
)

if __name__ == '__main__':
    # 加载模型
    model = Model().to(DEVICE)
    # 加载训练好的模型参数，这里假设你要加载最后一轮保存的参数，比如 epoch 为 99 时保存的（如果 EPOCH 设为 100 ）
    # 实际根据你保存的参数文件路径和想加载的 epoch 调整
    model.load_state_dict(torch.load("params/3bert.pt"))  
    model.eval()  # 切换到评估模式

    total_correct = 0
    total_count = 0
    with torch.no_grad():  # 评估时不需要计算梯度
        for input_ids, attention_mask, token_type_ids, labels in vail_laoder:
            # 将数据放到 DEVICE 上
            input_ids, attention_mask, token_type_ids, labels = input_ids.to(DEVICE), \
                                                                attention_mask.to(DEVICE), \
                                                                token_type_ids.to(DEVICE), \
                                                                labels.to(DEVICE)

            # 执行前向计算得到输出
            out = model(input_ids, attention_mask, token_type_ids)
            out = out.argmax(dim=1)  # 获取预测类别

            # 统计正确数量和总数量
            total_correct += (out == labels).sum().item()
            total_count += len(labels)

    # 计算准确率
    accuracy = total_correct / total_count
    print(f"验证集准确率为: {accuracy * 100:.2f}%")
    ```