tuxiangutil.py
```python
import matplotlib.pyplot as plt
import numpy as np
import torch
from torch import nn
import time
import copy
import torchvision.models as models

# 全局设备设置 - 自动检测并选择可用的设备（GPU或CPU）
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
    """
    初始化预训练模型
    
    参数:
        model_name (str): 模型名称 (目前仅支持'resnet')
        num_classes (int): 输出类别数量
        feature_extract (bool): 是否冻结预训练模型的权重
        use_pretrained (bool): 是否使用预训练权重
    
    返回:
        model: 初始化后的模型
        int: 模型的输入尺寸 (固定为64)
    """
    # 加载预训练的ResNet-18模型
    model = models.resnet18(pretrained=use_pretrained)
    # 根据特征提取模式设置参数是否需要梯度
    set_parameter_requires_grad(model, feature_extract)
    # 获取全连接层的输入特征数
    num_ftrs = model.fc.in_features
    # 替换最后一层全连接层，适配新的分类任务
    model.fc = nn.Linear(num_ftrs, num_classes)
    return model, 64  # 输入尺寸固定为64x64
def set_parameter_requires_grad(model, feature_extracting):
    """
    冻结模型参数
    
    参数:
        model: 要设置的模型
        feature_extracting (bool): 如果为True，则冻结所有参数
    """
    if feature_extracting:
        # 冻结所有参数 - 在反向传播时不更新这些参数
        for param in model.parameters():
            param.requires_grad = False

def train_model(model, dataloaders, criterion, optimizer, scheduler, 
                num_epochs=25, filename='best.pt'):
    """
    模型训练函数
    
    参数:
        model: 要训练的模型
        dataloaders (dict): 包含'train'和'valid'数据加载器的字典
        criterion: 损失函数
        optimizer: 优化器
        scheduler: 学习率调度器
        num_epochs (int): 训练轮数
        filename (str): 模型保存路径
    
    返回:
        model: 训练完成后的最佳模型
    """
    # 初始化最佳准确率和最佳模型权重
    best_acc = 0.0
    best_model_wts = copy.deepcopy(model.state_dict())
    
    # 遍历每个epoch
    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch+1}/{num_epochs}')
        print('-' * 10)
        
        # 分别处理训练和验证阶段
        for phase in ['train', 'valid']:
            if phase == 'train':
                model.train()  # 设置模型为训练模式
                scheduler.step()  # 更新学习率
            else:
                model.eval()   # 设置模型为评估模式
                
            # 初始化统计变量
            running_loss = 0.0
            running_corrects = 0
            
            # 遍历数据加载器中的所有批次
            for inputs, labels in dataloaders[phase]:
                # 将数据移动到指定设备
                inputs, labels = inputs.to(device), labels.to(device)
                
                # 梯度归零
                optimizer.zero_grad()
                
                # 根据阶段设置梯度计算状态
                with torch.set_grad_enabled(phase == 'train'):
                    # 前向传播
                    outputs = model(inputs)
                    # 计算损失
                    loss = criterion(outputs, labels)
                    # 获取预测结果
                    _, preds = torch.max(outputs, 1)
                    
                    # 如果是训练阶段，执行反向传播和优化
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                
                # 累计损失和正确预测数
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            
            # 计算epoch的平均损失和准确率
            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)
            
            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')
            
            # 如果是验证阶段且当前准确率优于历史最佳，保存模型
            if phase == 'valid' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())
                torch.save({
                    'state_dict': model.state_dict(),  # 模型权重
                    'best_acc': best_acc,             # 最佳准确率
                    'optimizer': optimizer.state_dict()  # 优化器状态
                }, filename)
        
        # 打印当前学习率
        print(f'LR: {optimizer.param_groups[0]["lr"]:.6f}')
    
    # 训练完成，输出最佳验证准确率
    print(f'Best val Acc: {best_acc:.4f}')
    # 加载最佳模型权重
    model.load_state_dict(best_model_wts)
    return model

def im_convert(tensor):
    """
    将张量转换为可显示的图像
    
    参数:
        tensor: 输入张量 (形状为 [C, H, W])
    
    返回:
        np.array: 转换后的图像数组 (形状为 [H, W, C])
    """
    # 将张量移回CPU并解耦梯度
    image = tensor.cpu().clone().detach()
    # 转换为numpy数组并去除多余的维度
    image = image.numpy().squeeze()
    # 调整维度顺序: (C, H, W) -> (H, W, C)
    image = image.transpose(1, 2, 0)
    # 反标准化处理: 还原原始像素值
    image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
    # 将像素值限制在[0,1]范围内
    image = image.clip(0, 1)
    return image

def visualize_predictions(images, labels, preds, cat_to_name, num_images=8):
    """
    可视化预测结果
    
    参数:
        images: 图像张量 (形状为 [B, C, H, W])
        labels: 真实标签 (形状为 [B])
        preds: 预测标签 (形状为 [B])
        cat_to_name (dict): 类别ID到名称的映射
        num_images (int): 要显示的图像数量
    """
    # 创建图形
    fig = plt.figure(figsize=(15, 15))
    
    # 只取前num_images个图像
    images = images[:num_images]
    labels = labels[:num_images]
    preds = preds[:num_images]
    
    # 遍历每个图像
    for idx in range(min(num_images, len(images))):
        # 创建子图 (4行4列布局)
        ax = fig.add_subplot(4, 4, idx+1, xticks=[], yticks=[])
        
        # 转换张量为可显示图像
        img = im_convert(images[idx])
        # 显示图像
        plt.imshow(img)
        
        # 获取真实标签和预测标签
        true_label = labels[idx].item()
        pred_label = preds[idx]
        
        # 从映射字典获取类别名称，如果不存在则使用默认值
        true_name = cat_to_name.get(str(true_label), f"未知类别 {true_label}")
        pred_name = cat_to_name.get(str(pred_label), f"未知类别 {pred_label}")
        
        # 根据预测是否正确设置标题颜色
        color = "green" if true_label == pred_label else "red"
        # 设置子图标题
        ax.set_title(f"真实: {true_name}\n预测: {pred_name}", color=color)
    
    # 调整布局
    plt.tight_layout()
    # 保存图像
    plt.savefig('predictions.png')
    print("预测结果已保存为 predictions.png")
    # 显示图像
    plt.show()
```
tuxaintran.py文件
```python
import os  # 操作系统接口，用于文件路径操作
import time  # 时间相关功能，用于计时
import copy  # 对象复制，用于模型状态保存
import json  # JSON数据处理，用于读取类别映射
import torch  # PyTorch深度学习框架
import torch.optim as optim  # 优化器模块
import torchvision  # 计算机视觉库
from torchvision import transforms, models, datasets  # 图像变换、预训练模型和数据集
from tuxiangutil import initialize_model, train_model, im_convert  # 自定义工具函数
from torch import nn  # 神经网络模块
import matplotlib.pyplot as plt  # 绘图库，用于可视化

# ============================================
# 配置设置部分
# ============================================
# 数据集路径 - 使用绝对路径确保可移植性
data_dir = '/data/home/zengxiangxi/xuexi/damoxing/flower_data'
# 批次大小 - 较大的批次大小可以加速训练但需要更多显存
batch_size = 128
# 模型名称 - 这里使用ResNet架构
model_name = 'resnet'
# 特征提取模式 - True表示冻结预训练模型的权重，只训练最后一层
feature_extract = True
# 分类类别数 - 对应花卉数据集的102个类别
num_classes = 102
# 设备选择 - 优先使用GPU加速训练
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# 模型保存文件名
filename = 'best.pth'

# ============================================
# 数据预处理部分
# ============================================
# 定义训练集和验证集的数据增强/预处理管道
data_transforms = {
    'train': transforms.Compose([
        # 训练集增强策略:
        transforms.Resize([96, 96]),  # 调整图像尺寸，为后续裁剪做准备
        transforms.RandomRotation(45),  # 随机旋转增强，增加模型鲁棒性
        transforms.CenterCrop(64),  # 中心裁剪，统一输入尺寸
        transforms.RandomHorizontalFlip(p=0.5),  # 50%概率水平翻转
        transforms.RandomVerticalFlip(p=0.5),  # 50%概率垂直翻转
        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),  # 颜色扰动
        transforms.RandomGrayscale(p=0.025),  # 2.5%概率转为灰度图
        transforms.ToTensor(),  # 转换为PyTorch张量 (0-1范围)
        # 标准化 - 使用ImageNet的均值和标准差，使输入数据符合预训练模型的要求
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'valid': transforms.Compose([
        # 验证集预处理 (无增强):
        transforms.Resize([64, 64]),  # 调整尺寸至模型输入大小
        transforms.ToTensor(),  # 转换为张量
        # 标准化 - 使用与训练集相同的参数
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# ============================================
# 数据加载部分
# ============================================
# 创建数据集对象 - ImageFolder自动根据文件夹结构分类
image_datasets = {
    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) 
    for x in ['train', 'valid']  # 分别处理训练集和验证集
}

# 创建数据加载器 - 负责批量加载数据
dataloaders = {
    x: torch.utils.data.DataLoader(
        image_datasets[x], 
        batch_size=batch_size, 
        shuffle=True  # 打乱数据顺序，避免模型学习到顺序偏差
    ) 
    for x in ['train', 'valid']
}

# 计算数据集大小 - 用于统计和评估
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}
# 获取类别名称 - 从文件夹名称获取
class_names = image_datasets['train'].classes

# 加载类别ID到名称的映射 - 用于结果可视化
with open('cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)

# ============================================
# 模型初始化部分
# ============================================
# 初始化预训练模型 - 使用自定义函数
model_ft, input_size = initialize_model(
    model_name, 
    num_classes, 
    feature_extract, 
    use_pretrained=True  # 使用预训练权重
)
# 将模型移到相应设备 (GPU/CPU)
model_ft = model_ft.to(device)
print(f"使用设备: {device} 进行训练")

# ============================================
# 第一阶段训练 - 只训练全连接层
# ============================================
print("\n=== 第一阶段: 仅训练全连接层 ===")
# 创建优化器 - 只优化需要梯度的参数 (即新添加的全连接层)
optimizer_ft = optim.Adam(
    filter(lambda p: p.requires_grad, model_ft.parameters()), 
    lr=1e-2  # 初始学习率
)
# 学习率调度器 - 每10个epoch衰减一次学习率 (乘以0.1)
scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)
# 损失函数 - 交叉熵损失适用于分类任务
criterion = nn.CrossEntropyLoss()

# 训练模型 - 使用自定义训练函数
model_ft = train_model(
    model_ft,        # 要训练的模型
    dataloaders,     # 数据加载器
    criterion,       # 损失函数
    optimizer_ft,    # 优化器
    scheduler,       # 学习率调度器
    num_epochs=20,   # 训练轮数
    filename=filename # 模型保存路径
)

# ============================================
# 第二阶段训练 - 微调所有层
# ============================================
print("\n=== 第二阶段: 微调所有层 ===")
# 解冻所有层参数 - 允许所有层参与训练
for param in model_ft.parameters():
    param.requires_grad = True

# 创建新的优化器 - 优化所有参数 (包括预训练部分)
optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-3)  # 使用更小的学习率
# 新的学习率调度器 - 每7个epoch衰减一次
scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# 加载第一阶段训练的最佳模型 - 作为微调的起点
checkpoint = torch.load(filename)
model_ft.load_state_dict(checkpoint['state_dict'])

# 进行微调训练 - 使用相同的训练函数
model_ft = train_model(
    model_ft, 
    dataloaders, 
    criterion, 
    optimizer_ft, 
    scheduler, 
    num_epochs=20, 
    filename=filename
)

# ============================================
# 模型评估与可视化
# ============================================
# 加载最终的最佳模型 - 使用验证集上表现最好的模型
checkpoint = torch.load(filename)
model_ft.load_state_dict(checkpoint['state_dict'])
# 设置为评估模式 - 禁用dropout和batchnorm的随机性
model_ft.eval()

# 从验证集获取一个批次的数据
dataiter = iter(dataloaders['valid'])
images, labels = next(dataiter)  # 获取下一批数据
# 将数据移动到相应设备 (GPU/CPU)
images, labels = images.to(device), labels.to(device)

# 禁用梯度计算 - 节省内存和计算资源，加速推理
with torch.no_grad():
    # 前向传播获取预测
    outputs = model_ft(images)
# 获取预测类别 - 选择概率最高的类别
_, preds_tensor = torch.max(outputs, 1)  # dim=1表示在类别维度取最大值
# 将预测结果转换为numpy数组 (便于后续处理)
preds = preds_tensor.cpu().numpy()

# 可视化预测结果 - 展示模型性能
print("\n可视化预测结果...")
# 显示前8个样本的预测结果 - 使用自定义可视化函数
#im_convert(images, labels, preds, cat_to_name, num_images=8)
visualize_predictions(images, labels, preds, cat_to_name, num_images=8)
```