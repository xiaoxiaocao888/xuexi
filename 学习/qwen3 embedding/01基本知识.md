**文本嵌入模型**：将文本(词语、句子、文档)转换为能够捕捉其语义信息的数值向量。可以想象成在“语义空间”中给每段文本一个坐标、相似的文本在空间中距离更近。
**文本重排序**：当我们为一个查询检索到一组候选文档后，重排序会更仔细地审查这些候选文档，将最相关的结果排在最前面。

**qwen3 embedding模型的创新**
- 基于qwen3基础模型(参数规模包括0.6B、4B、8B)构建，支持的序列长度都是32K，对应的向量维度分别为1024、2560、4096.
- 创新的多阶段训练流程：
     - 结合了大规模无监督预训练(基于合成数据)和高质量数据集上的监督微调
     - 引入了基于不同检查点的模型合并(model merging)技术(使用slerp)，以增强模型的鲁棒性和泛化能力。
     - LLM驱动的数据合成：利用Qwen3-32B本身合成了大规模、高质量、多样化的多领域、多语言训练数据。极大增强了训练流程的效果
     - 达到SOTA性能：在多个基准测试中取得了当前最佳(State-of-the-Art,SOTA)的结果。尤其在多语言文本嵌入基准MTEB(Massive Text Embedding Benchmark)上表现优异，在代码检索、跨语言检索和多语言检索等任务中表现出色。

##### 模型架构
Qwen3 Embedding系列模型是Decoder-only的LLM。
**嵌入模型**
- 使用具有因果注意力(Causal Attention)的LLM
- 在输入序列末尾附加一个`[EOS]`(End Of Sequence)标记(用于表征整个序列的语义信息)，最终的嵌入向量来源于最后一层对应于此`[EOS]` 标记的隐状态。
- **指令遵循(Instruction Following)**: 为了使嵌入具备任务感知能力，指令会与查询拼接。查询输入格式：`{Instruction} {Query}<|endoftext|>` 文档输入格式：`{Document}<|endoftext|> (文档独立处理)

**重排序模型(reranking models)**
- 利用LLM进行逐点重排序(point-wise reranking) (一次评估一个查询-文档对)
- 任务被构建为一个二分类问题：预测“yes" (相关) 或”no“ （不相关）
- 输入遵循LLM的聊天模板，包含指令、查询和文档（系统提示、用户输入、模型推理）
```
<|im_start|>system
根据Query和提供的Instruct判断Document是否满足要求。注意，答案只能是"yes"或"no"<|im_end|>
<|im_start|>user
<Instuct>:{Instruction}
<Query>:{Query}
<Document>:{Document}<|im_end|>
<|im_start|>assistant
<think>\n\n</think>\n\n
```
- 相关性得分基于下一个词元是"yes"与"no"的似然性

**模型配置**
所有模型都具备"指令感知”能力。嵌入模型支持多表示层支持(自定义维度)
- 指令感知(Instruction Aware):支持用户根据不同任务定制输入指令，使模型能够更好地适应特定场景的需求
- 多表示层支持(MRL Support):Embedding模型支持自定义最终输出的嵌入维度，这为不同应用场景下的效率和存储需求提供了灵活性


**训练流程**
embedding和reranking模型采用多阶段训练方法
**阶段一**大规模合成数据驱动的弱监督预训练(仅嵌入模型)
- 与以往依赖问答论坛等数据的工作不同，Qwen3利用其强大的Qwen3-32B模型直接合成了约1.5亿个文本对。
**阶段二**监督微调(embedding和ranking)
- 使用规模较小但质量更高的数据集
- 除了精心筛选的人工标注数据集(约700万对)，还选择性地引入了高质量的合成数据(从阶段一筛选得到，通过余弦相似度大于0.7的标准筛选出约1200万对高质量数据)
**阶段三**模型合并(embedding和ranking)
- 在监督微调完成后，采用基于球面线性插值(slerp)的模型融合技术，合并微调过程中保存的多个模型检查点，以提升模型的鲁棒性和泛化能力
- slerp简单理解：想象球面上有两个点(代码两个检查点的模型权重)。slerp会找到这两个点之间沿球面最短的路径。你可以选择这条路径上的某个中间点作为融合后的模型


##### 训练目标
**嵌入模型**（基于InfoNCE的对比损失）
InfoNCE是一种对比学习中的损失函数，用于最大化正样本之间的相似度，同时最小化与负样本之间的相似度。
目标是在嵌入空间中拉近正样本对(查询，相关文档)的距离，同时推开负样本对(查询，不相关文档)的距离
![[Pasted image 20250704113526.png]]
硬负样本指的是一些文档和查询q i的语义完全不一致
同批次内其他查询作为负样本：其他查询q j 和其他文档组合
同批次内其他文档作为di+的负样本：会把当前查询相关的文档和其他不相关的文档也会组成一对一对

**重排序模型**(监督微调损失)
![[Pasted image 20250704113756.png]]

##### 实验设计与结果
###### 评估设置
- 主要基准(嵌入模型)：MMTEB(Massive Multilingual Text Embedding Ebnchmark)
     - 覆盖超过250种语言，包含超过500个评估任务
     - 评估的子集包括：MTEB多语言(131个任务)；MTEB英语v2(41个任务)；CMTEB(中文，32个任务)；MTEB代码(12个代码检索任务)
 - 重排序任务
     - 基础相关性检索：MTEB，CMTEB，MMTEB的检索子集，MLDR
     - 代码检索：METB-Code
     - 复杂指令检索：FollowIR