##### 通用大模型
**大模型**：是指在深度学习中具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务，如自然语言处理、计算机视觉和语音识别等。这些模型的参数数量通常在数亿到数千亿之间，能够从海量数据中学习到丰富的特征和模式
###### 按照应用领域分类
**语言大模型(NLP)**:专注于自然语言处理任务，如文本生成、问答和翻译。(GPT-3 4、BERT)
**视觉大模型(CV)**：用于图像处理和分析的模型，如图像分类、目标检测等(ResNet、VGG)
**多模态大模型**：能够处理多种类型数据(如文本、图像、音频)的模型。(如CLIP 结合图像和文本的理解和DALL-E 生成图像的模型)
###### 按照模型规模分类
**通用大模型**：可在多个领域和任务上通用的大模型，具有较强的泛化能力。
**行业大模型**：针对特定行业或领域进行优化的大模型，通常使用行业相关的数据进行预训练和微调，能够更好地理解行业特有的术语、数据和上下文，从而提供更精准的结果
**垂直大模型**：专注于某一行业特定任务或场景的大模型，通常使用任务相关的数据进行训练
大模型的训练需要大量的计算资源，通常依赖于高性能的GPU(图形处理单元)或TPU(张量处理单元)

**微调**：在预训练好的通用大模型基础上，用特定领域的小数据进一步训练，使其适配具体任务的技术
#### 微调的分类
##### 魔塔社区的约定
**base模型**：在预训练阶段使用大规模的数据集，学习通用的表示能力，通常需要大量的计算资源和时间
**instruct模型**：一般指的是指令微调的模型(常说的微调是这种)

##### 按微调策略分类
- **全参数微调**：更新模型的所有参数，适用于数据量充足、计算资源丰富的一个场景。容易过拟合
- **参数高效微调PEFT**：Parameter-Efficient Fine-Tuning.
     - LoRA:Low-Rank Adaptation。通过低秩矩阵分解的方式来更新权重，相对应更新的参数量会比较小一些。效率会更高。
     - QLoRA:量化+LoRA. 量化就是小数点后精确的位数更少。那么计算量更少、占用内存更少、训练和推理的时候效率都更高。
     - 适配器：Adapter. 在模型中插入一个小型的全连接层。会对原始模型权重全部冻结，改动更小。

##### 按数据利用方式分类
- **监督微调**：Supervised Fine-Tuning,SFT. 使用标注数据直接微调(如指令微调)里面有很多不同的数据格式
- **无监督/自监督微调**：利用无标签数据继续训练，适用于领域适应的这种微调。
- **强化学习微调(RLHF、DPO、PPO)**：人类反馈的这种强化学习，自动偏好等等


##### 微调工作的干法：
- 在云上用云服务商提供的工具做预训练
    如阿里的百炼平台(https://bailian.console.aliyun.com/)、硅基流动提供的在线微调
- 下载微调工具到本地训练
     如北航开源的LLama factory(https://github.com/hiyouga/LLaMA-Factory)、阿里云的swift
- 通过自主可控

##### 微调与RAG的区别
**RAG**：主要整合的是对知识库内容进行整合、汇总后输出(适用于动态需要更新的数据、可解释性即可追溯到使用的是哪个文档、通用性)
**微调**：是对 定制化模型的问答，是模型经过训练学习到的内容(适用于要有特色)
微调的成本高于RAG，延迟低
微调和RAG是可以一起组合使用的。
![[Pasted image 20250602221547.png]]