```python
import asyncio
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chat_models import init_chat_model
from langchain_core.output_parsers import StrOutputParser
# 初始化模型和解析器
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")
parser = StrOutputParser()
# 创建提示模板
prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="你叫小智，是一名乐于助人的助手。"),
    MessagesPlaceholder(variable_name="messages"),
])
# 构建链
chain = prompt | model | parser
# 异步聊天主函数
async def chat():
    messages_list = []  # 初始化历史
    print("🔹 输入 exit 结束对话")
    while True:
        # 获取用户输入
        user_query = input("👤 你：")
        if user_query.lower() in {"exit", "quit"}:
            break
        # 添加用户消息
        messages_list.append(HumanMessage(content=user_query))
        # 流式输出AI回复
        print("🤖 小智：", end="", flush=True)
        full_reply = ""
        # 流式处理回复
        async for chunk in chain.astream({"messages": messages_list}):
            print(chunk, end="", flush=True)
            full_reply += chunk
        # 添加AI回复到历史
        messages_list.append(AIMessage(content=full_reply))
        print()  # 换行
        # 限制历史长度
        messages_list = messages_list[-50:]
# 启动聊天
if __name__ == "__main__":
    asyncio.run(chat())
    ```
如果要流式打印，只需要在调用模型时将`invoke`方法替换为`astream`方法，然后使用`async for`循环来获取模型的输出即可。
![[Pasted image 20250701155955.png]]
##### 使用`gradio`来开发一个支持在网页上进行交互的问答机器人。
```bash
pip install gradio
```
运行后，在浏览器访问`http://127.0.0.1:7860`即可进行问答交互。
- `init_chat_model`：初始化 DeepSeek 等聊天模型。
- `ChatPromptTemplate`：用于构建聊天 Prompt 模板。
- `MessagesPlaceholder`：用于占位历史消息。
- `HumanMessage` / `AIMessage`：构建多轮消息结构。
- `StrOutputParser`：将模型输出转换为字符串。
- `gradio`：构建网页界面。
-  **SystemMessage**：初始化系统角色设定（小智）。
- **MessagesPlaceholder**：用变量名 `messages` 占位历史消息。会加载到提示词里面
- **qa_chain**：组合为 LangChain Expression Language 链。
- 我们用 `gr.State` 存储所有历史消息（列表）。每次用户发送消息，都会：
- append 一个 `HumanMessage`。    
- 流式调用模型并不断更新回复。
- append 一个 `AIMessage`。
- 最后裁剪：`messages_list = messages_list[-50:]`。
- **支持 async 流式输出**。
- **动态更新最后一轮对话**。
- **通过** **`yield`** **实时反馈到前端**。
- 清空历史函数，用于点击 "清空" 按钮时重置历史记录、输入框和消息状态。
- **事件绑定**：用户提交文本 → 调用 `respond` → 返回新状态。
- **Gradio Chatbot 组件**：使用 `avatar_images` 设置人机头像。
- **Gradio State**：跨组件共享并持久化消息列表。
![[Pasted image 20250701161116.png]]
```Python
import gradio as gr
from langchain.chat_models import init_chat_model
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# ──────────────────────────────────────────────
# 1. 模型、Prompt、Chain
# ──────────────────────────────────────────────
model = init_chat_model("deepseek-chat", model_provider="deepseek")
parser = StrOutputParser()

chatbot_prompt = ChatPromptTemplate.from_messages(
    [
        SystemMessage(content="你叫小智，是一名乐于助人的助手。"),
        MessagesPlaceholder(variable_name="messages"),  # 手动传入历史
    ]
)

qa_chain = chatbot_prompt | model | parser   # LCEL 组合

# ──────────────────────────────────────────────
# 2. Gradio 组件
# ──────────────────────────────────────────────
CSS = """
.main-container {max-width: 1200px; margin: 0 auto; padding: 20px;}
.header-text {text-align: center; margin-bottom: 20px;}
"""

def create_chatbot() -> gr.Blocks:
    with gr.Blocks(title="DeepSeek Chat", css=CSS) as demo:
        with gr.Column(elem_classes=["main-container"]):
            gr.Markdown("# 🤖 LangChain B站公开课 By九天Hector", elem_classes=["header-text"])
            gr.Markdown("基于 LangChain LCEL 构建的流式对话机器人", elem_classes=["header-text"])

            chatbot = gr.Chatbot(
                height=500,
                show_copy_button=True,
                avatar_images=(
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f464.png",
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png",
                ),
            )
            msg = gr.Textbox(placeholder="请输入您的问题...", container=False, scale=7)
            submit = gr.Button("发送", scale=1, variant="primary")
            clear = gr.Button("清空", scale=1)

        # ---------------  状态：保存 messages_list  ---------------
        state = gr.State([])          # 这里存放真正的 Message 对象列表

        # ---------------  主响应函数（流式） ----------------------
        async def respond(user_msg: str, chat_hist: list, messages_list: list):
            # 1) 输入为空直接返回
            if not user_msg.strip():
                yield "", chat_hist, messages_list
                return

            # 2) 追加用户消息
            messages_list.append(HumanMessage(content=user_msg))
            chat_hist = chat_hist + [(user_msg, None)]
            yield "", chat_hist, messages_list      # 先显示用户消息

            # 3) 流式调用模型
            partial = ""
            async for chunk in qa_chain.astream({"messages": messages_list}):
                partial += chunk
                # 更新最后一条 AI 回复
                chat_hist[-1] = (user_msg, partial)
                yield "", chat_hist, messages_list

            # 4) 完整回复加入历史，裁剪到最近 50 条
            messages_list.append(AIMessage(content=partial))
            messages_list = messages_list[-50:]

            # 5) 最终返回（Gradio 需要把新的 state 传回）
            yield "", chat_hist, messages_list

        # ---------------  清空函数 -------------------------------
        def clear_history():
            return [], "", []          # 清空 Chatbot、输入框、messages_list

        # ---------------  事件绑定 ------------------------------
        msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])
        submit.click(respond, [msg, chatbot, state], [msg, chatbot, state])
        clear.click(clear_history, outputs=[chatbot, msg, state])

    return demo


# ──────────────────────────────────────────────
# 3. 启动应用
# ──────────────────────────────────────────────
demo = create_chatbot()
demo.launch(server_name="0.0.0.0", server_port=7860, share=False, debug=True)
```