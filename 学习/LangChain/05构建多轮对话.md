```python
import asyncio
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chat_models import init_chat_model
from langchain_core.output_parsers import StrOutputParser
# åˆå§‹åŒ–æ¨¡å‹å’Œè§£æå™¨
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")
parser = StrOutputParser()
# åˆ›å»ºæç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    SystemMessage(content="ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
    MessagesPlaceholder(variable_name="messages"),
])
# æ„å»ºé“¾
chain = prompt | model | parser
# å¼‚æ­¥èŠå¤©ä¸»å‡½æ•°
async def chat():
    messages_list = []  # åˆå§‹åŒ–å†å²
    print("ğŸ”¹ è¾“å…¥ exit ç»“æŸå¯¹è¯")
    while True:
        # è·å–ç”¨æˆ·è¾“å…¥
        user_query = input("ğŸ‘¤ ä½ ï¼š")
        if user_query.lower() in {"exit", "quit"}:
            break
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages_list.append(HumanMessage(content=user_query))
        # æµå¼è¾“å‡ºAIå›å¤
        print("ğŸ¤– å°æ™ºï¼š", end="", flush=True)
        full_reply = ""
        # æµå¼å¤„ç†å›å¤
        async for chunk in chain.astream({"messages": messages_list}):
            print(chunk, end="", flush=True)
            full_reply += chunk
        # æ·»åŠ AIå›å¤åˆ°å†å²
        messages_list.append(AIMessage(content=full_reply))
        print()  # æ¢è¡Œ
        # é™åˆ¶å†å²é•¿åº¦
        messages_list = messages_list[-50:]
# å¯åŠ¨èŠå¤©
if __name__ == "__main__":
    asyncio.run(chat())
    ```
å¦‚æœè¦æµå¼æ‰“å°ï¼Œåªéœ€è¦åœ¨è°ƒç”¨æ¨¡å‹æ—¶å°†`invoke`æ–¹æ³•æ›¿æ¢ä¸º`astream`æ–¹æ³•ï¼Œç„¶åä½¿ç”¨`async for`å¾ªç¯æ¥è·å–æ¨¡å‹çš„è¾“å‡ºå³å¯ã€‚
![[Pasted image 20250701155955.png]]
##### ä½¿ç”¨`gradio`æ¥å¼€å‘ä¸€ä¸ªæ”¯æŒåœ¨ç½‘é¡µä¸Šè¿›è¡Œäº¤äº’çš„é—®ç­”æœºå™¨äººã€‚
```bash
pip install gradio
```
è¿è¡Œåï¼Œåœ¨æµè§ˆå™¨è®¿é—®`http://127.0.0.1:7860`å³å¯è¿›è¡Œé—®ç­”äº¤äº’ã€‚
- `init_chat_model`ï¼šåˆå§‹åŒ– DeepSeek ç­‰èŠå¤©æ¨¡å‹ã€‚
- `ChatPromptTemplate`ï¼šç”¨äºæ„å»ºèŠå¤© Prompt æ¨¡æ¿ã€‚
- `MessagesPlaceholder`ï¼šç”¨äºå ä½å†å²æ¶ˆæ¯ã€‚
- `HumanMessage` / `AIMessage`ï¼šæ„å»ºå¤šè½®æ¶ˆæ¯ç»“æ„ã€‚
- `StrOutputParser`ï¼šå°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚
- `gradio`ï¼šæ„å»ºç½‘é¡µç•Œé¢ã€‚
-  **SystemMessage**ï¼šåˆå§‹åŒ–ç³»ç»Ÿè§’è‰²è®¾å®šï¼ˆå°æ™ºï¼‰ã€‚
- **MessagesPlaceholder**ï¼šç”¨å˜é‡å `messages` å ä½å†å²æ¶ˆæ¯ã€‚ä¼šåŠ è½½åˆ°æç¤ºè¯é‡Œé¢
- **qa_chain**ï¼šç»„åˆä¸º LangChain Expression Language é“¾ã€‚
- æˆ‘ä»¬ç”¨ `gr.State` å­˜å‚¨æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆåˆ—è¡¨ï¼‰ã€‚æ¯æ¬¡ç”¨æˆ·å‘é€æ¶ˆæ¯ï¼Œéƒ½ä¼šï¼š
- append ä¸€ä¸ª `HumanMessage`ã€‚    
- æµå¼è°ƒç”¨æ¨¡å‹å¹¶ä¸æ–­æ›´æ–°å›å¤ã€‚
- append ä¸€ä¸ª `AIMessage`ã€‚
- æœ€åè£å‰ªï¼š`messages_list = messages_list[-50:]`ã€‚
- **æ”¯æŒ async æµå¼è¾“å‡º**ã€‚
- **åŠ¨æ€æ›´æ–°æœ€åä¸€è½®å¯¹è¯**ã€‚
- **é€šè¿‡** **`yield`** **å®æ—¶åé¦ˆåˆ°å‰ç«¯**ã€‚
- æ¸…ç©ºå†å²å‡½æ•°ï¼Œç”¨äºç‚¹å‡» "æ¸…ç©º" æŒ‰é’®æ—¶é‡ç½®å†å²è®°å½•ã€è¾“å…¥æ¡†å’Œæ¶ˆæ¯çŠ¶æ€ã€‚
- **äº‹ä»¶ç»‘å®š**ï¼šç”¨æˆ·æäº¤æ–‡æœ¬ â†’ è°ƒç”¨ `respond` â†’ è¿”å›æ–°çŠ¶æ€ã€‚
- **Gradio Chatbot ç»„ä»¶**ï¼šä½¿ç”¨ `avatar_images` è®¾ç½®äººæœºå¤´åƒã€‚
- **Gradio State**ï¼šè·¨ç»„ä»¶å…±äº«å¹¶æŒä¹…åŒ–æ¶ˆæ¯åˆ—è¡¨ã€‚
![[Pasted image 20250701161116.png]]
```Python
import gradio as gr
from langchain.chat_models import init_chat_model
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. æ¨¡å‹ã€Promptã€Chain
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model = init_chat_model("deepseek-chat", model_provider="deepseek")
parser = StrOutputParser()

chatbot_prompt = ChatPromptTemplate.from_messages(
    [
        SystemMessage(content="ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"),
        MessagesPlaceholder(variable_name="messages"),  # æ‰‹åŠ¨ä¼ å…¥å†å²
    ]
)

qa_chain = chatbot_prompt | model | parser   # LCEL ç»„åˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Gradio ç»„ä»¶
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CSS = """
.main-container {max-width: 1200px; margin: 0 auto; padding: 20px;}
.header-text {text-align: center; margin-bottom: 20px;}
"""

def create_chatbot() -> gr.Blocks:
    with gr.Blocks(title="DeepSeek Chat", css=CSS) as demo:
        with gr.Column(elem_classes=["main-container"]):
            gr.Markdown("# ğŸ¤– LangChain Bç«™å…¬å¼€è¯¾ Byä¹å¤©Hector", elem_classes=["header-text"])
            gr.Markdown("åŸºäº LangChain LCEL æ„å»ºçš„æµå¼å¯¹è¯æœºå™¨äºº", elem_classes=["header-text"])

            chatbot = gr.Chatbot(
                height=500,
                show_copy_button=True,
                avatar_images=(
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f464.png",
                    "https://cdn.jsdelivr.net/gh/twitter/twemoji@v14.0.2/assets/72x72/1f916.png",
                ),
            )
            msg = gr.Textbox(placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", container=False, scale=7)
            submit = gr.Button("å‘é€", scale=1, variant="primary")
            clear = gr.Button("æ¸…ç©º", scale=1)

        # ---------------  çŠ¶æ€ï¼šä¿å­˜ messages_list  ---------------
        state = gr.State([])          # è¿™é‡Œå­˜æ”¾çœŸæ­£çš„ Message å¯¹è±¡åˆ—è¡¨

        # ---------------  ä¸»å“åº”å‡½æ•°ï¼ˆæµå¼ï¼‰ ----------------------
        async def respond(user_msg: str, chat_hist: list, messages_list: list):
            # 1) è¾“å…¥ä¸ºç©ºç›´æ¥è¿”å›
            if not user_msg.strip():
                yield "", chat_hist, messages_list
                return

            # 2) è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
            messages_list.append(HumanMessage(content=user_msg))
            chat_hist = chat_hist + [(user_msg, None)]
            yield "", chat_hist, messages_list      # å…ˆæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯

            # 3) æµå¼è°ƒç”¨æ¨¡å‹
            partial = ""
            async for chunk in qa_chain.astream({"messages": messages_list}):
                partial += chunk
                # æ›´æ–°æœ€åä¸€æ¡ AI å›å¤
                chat_hist[-1] = (user_msg, partial)
                yield "", chat_hist, messages_list

            # 4) å®Œæ•´å›å¤åŠ å…¥å†å²ï¼Œè£å‰ªåˆ°æœ€è¿‘ 50 æ¡
            messages_list.append(AIMessage(content=partial))
            messages_list = messages_list[-50:]

            # 5) æœ€ç»ˆè¿”å›ï¼ˆGradio éœ€è¦æŠŠæ–°çš„ state ä¼ å›ï¼‰
            yield "", chat_hist, messages_list

        # ---------------  æ¸…ç©ºå‡½æ•° -------------------------------
        def clear_history():
            return [], "", []          # æ¸…ç©º Chatbotã€è¾“å…¥æ¡†ã€messages_list

        # ---------------  äº‹ä»¶ç»‘å®š ------------------------------
        msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])
        submit.click(respond, [msg, chatbot, state], [msg, chatbot, state])
        clear.click(clear_history, outputs=[chatbot, msg, state])

    return demo


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. å¯åŠ¨åº”ç”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
demo = create_chatbot()
demo.launch(server_name="0.0.0.0", server_port=7860, share=False, debug=True)
```