ä½¿ç”¨langchain æ­å»ºragæ˜¯æ¯”è¾ƒç®€å•çš„ï¼Œé‡Œé¢ä½¿ç”¨å¼€æºæ¡†æ¶æ¥åšçš„ã€‚
ç›´æ¥æ£€ç´¢çš„é—®é¢˜æœ‰ï¼šæ— æ•ˆä¿¡æ¯å¤šï¼Œè¶Šå¤šå¯¹å¤§æ¨¡å‹åç»­çš„æ¨ç†å½±å“è¶Šå¤§ï¼›å­˜åœ¨æœ€å¤§tokené™åˆ¶ã€‚
è§£å†³ï¼šæŠŠå­˜æ”¾ç€åŸå§‹æ•°æ®çš„çŸ¥è¯†åº“(knowledge)ä¸­çš„æ¯ä¸€ä¸ªraw dataï¼Œåˆ‡åˆ†æˆä¸€ä¸ªä¸€ä¸ªçš„å°å—ï¼Œè¿™äº›å°å—å¯ä»¥æ˜¯ä¸€ä¸ªæ®µè½ï¼Œä¹Ÿå¯ä»¥æ˜¯æ•°æ®åº“ä¸­æŸä¸ªç´¢å¼•å¯¹åº”çš„å€¼ã€‚è¯¥è¿‡ç¨‹ç§°ä¸º"åˆ†å—"ã€‚æˆ‘ä»¬æœ€ç»ˆå¾—åˆ°ä¸€ä¸ªå……æ»¡å—çš„æ•°æ®(chunks)çš„æ–°çš„çŸ¥è¯†åº“(repository)ã€‚å½“å†æ¥æ”¶åˆ°queryï¼Œå°±ä¼šåœ¨æ–°çŸ¥è¯†åº“é‡Œé¢æŸ¥æ‰¾ï¼Œè¿”å›ä¸€ä¸ªæˆ–å¤šä¸ªç‰¹å®šçš„chunkï¼Œä¿¡æ¯é‡å°±æ›´å°ä¸”æ›´ç²¾ç¡®ã€‚ç„¶åè¿™äº›chunkè¢«åŠ å…¥åˆ°promptä¸­ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯ä¸ç”¨äºåŸå§‹queryå…±åŒè¾“å…¥åˆ°å¤§æ¨¡å‹è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„å›ç­”ã€‚

åœ¨ä¸Šè¿°å°†åŸå§‹æ•°æ®ï¼ˆraw dataï¼‰è½¬åŒ–ä¸ºchunkçš„è¿‡ç¨‹ä¸­ï¼Œå°±åŒ…å«**æ„å»ºRAG**çš„ç¬¬ä¸€éƒ¨åˆ†å¼€å‘å·¥ä½œï¼š
åšæ•°æ®æ¸…æ´—ï¼Œå¦‚å»é™¤åœç”¨è¯ã€æ ‡ç‚¹ç¬¦å·ç­‰ã€‚å’Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„`split`æ–¹æ³•æ¥è¿›è¡Œæ•°æ®åˆ‡åˆ†çš„ä¸€ç³»åˆ—æŠ€æœ¯ã€‚
åœ¨NLPä¸­å»è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦çš„æœ‰æ•ˆçš„æ–¹æ³•å°±æ˜¯Embeddingï¼Œå³å°†è¿™äº›chunksè½¬æ¢æˆå‘é‡ï¼ˆvectorï¼‰å½¢å¼ã€‚
æ„å»ºRAGçš„ç¬¬ä¸‰éƒ¨åˆ†å·¥ä½œï¼šæˆ‘ä»¬è¦å»äº†è§£å’Œå­¦ä¹ å¦‚ä½•é€‰æ‹©ã€ä½¿ç”¨å‘é‡æ•°æ®åº“ã€‚ï¼ˆè§£å†³æœç´¢æ•ˆç‡å’Œè®¡ç®—ç›¸ä¼¼åº¦ä¼˜åŒ–ç®—æ³•ï¼‰
#### ä¸€ä¸ªåŸºç¡€çš„RAGæ¶æ„ä¼šåªè¦åŒ…å«ä»¥ä¸‹å‡ æ–¹é¢çš„å¼€å‘å·¥ä½œï¼š
1. å¦‚ä½•å°†åŸå§‹æ•°æ®è½¬åŒ–æˆchunksï¼›
2. å¦‚ä½•å°†chunksè½¬åŒ–æˆVectorï¼›
3. å¦‚ä½•é€‰æ‹©è®¡ç®—å‘é‡ç›¸ä¼¼åº¦çš„ç®—æ³•ï¼›
4. å¦‚ä½•åˆ©ç”¨å‘é‡æ•°æ®åº“æå‡æœç´¢æ•ˆç‡ï¼›
5. å¦‚ä½•æŠŠæ‰¾åˆ°çš„chunksä¸åŸå§‹queryæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œäº§ç”Ÿæœ€ç»ˆçš„Promptï¼›

![[Pasted image 20250703104249.png]]

##### æ”¯æŒ PDF æ–‡ä»¶è§£æçš„æ™ºèƒ½RAG é—®ç­”
æˆ‘ä»¬é€šè¿‡ `Streamlit` å‰ç«¯ç•Œé¢ï¼Œç»“åˆ `LangChain` æ¡†æ¶ ä¸ `DashScope` å‘é‡åµŒå…¥æœåŠ¡ï¼Œå®ç°äº†ä¸€ä¸ªè½»é‡åŒ–çš„ `RAGï¼ˆRetrieval-Augmented Generationï¼‰` æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒä¸Šä¼ å¤šä¸ª `PDF` æ–‡æ¡£ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å®Œæˆæ–‡æœ¬æå–ã€åˆ†å—ã€å‘é‡åŒ–ï¼Œå¹¶æ„å»ºåŸºäº `FAISS` çš„æ£€ç´¢æ•°æ®åº“ã€‚ç”¨æˆ·éšåå¯ä»¥åœ¨é¡µé¢ä¸­è¾“å…¥ä»»æ„é—®é¢˜ï¼Œç³»ç»Ÿä¼šè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ `DeepSeek-Chat`ï¼‰å¯¹ `PDF` å†…å®¹è¿›è¡Œè¯­ä¹‰ç†è§£å’Œå›ç­”ç”Ÿæˆã€‚

```Python
pip install streamlit PyPDF2 dashscope faiss-cpu
```
è¦è·å–DASHSCOPE_API_KEY=xxxï¼Œå†™å…¥.env
èƒ½å¤Ÿå®ç°ï¼š
- **LangChain çš„å¤šæ¨¡å—èƒ½åŠ›**ï¼ˆå‘é‡æœç´¢ + Agentå·¥å…·ï¼‰
- **Streamlit å‰ç«¯äº¤äº’**
- **FAISS å‘é‡æ•°æ®åº“**
- **DashScope Embedding + DeepSeek æ¨¡å‹æ¥å…¥**
- å¹¶å®Œæˆäº†å®Œæ•´çš„ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æµç¨‹

 `PyPDF2` ç”¨æ¥è¯»å– PDF æ–‡æœ¬ã€‚
 è®¾ç½® `KMP_DUPLICATE_LIB_OK` é¿å…æŸäº› MKL å¤šçº¿ç¨‹æŠ¥é”™ã€‚
 ç”¨é˜¿é‡Œäº‘ DashScope æä¾›çš„ `text-embedding-v1` å°†æ–‡æœ¬è½¬ä¸ºå‘é‡è¡¨ç¤ºï¼Œç”¨äºç›¸ä¼¼åº¦æœç´¢ã€‚
`pdf_read`ï¼šé€é¡µè¯»å– PDF å†…å®¹å¹¶æ‹¼æ¥ã€‚
`get_chunks`ï¼šå°†é•¿æ–‡æœ¬åˆ‡ç‰‡ä¸ºå¤šä¸ªæ®µè½ï¼ˆchunkï¼‰ï¼Œæ¯æ®µ 1000 å­—ï¼Œé‡å  200 å­—ã€‚(é¿å…ä¸€äº›é‡è¦ä¿¡æ¯è¢«æˆªæ–­)
`vector_store`ï¼šç”¨ FAISS å»ºç«‹å‘é‡ç´¢å¼•ï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ° `faiss_db/`ã€‚
`user_input`: åŠ è½½æœ¬åœ° FAISS å‘é‡åº“ï¼› å°†å…¶è½¬ä¸º LangChain çš„æ£€ç´¢å·¥å…·ï¼› äº¤ç”± Agent è°ƒç”¨å®Œæˆå›ç­”ã€‚
ä¸»å‡½æ•°ï¼šé¡µé¢æ ‡é¢˜ä¸ç•Œé¢é…ç½®ã€‚`st.columns` åˆ†æ ï¼šå·¦è¾¹æ˜¾ç¤ºæç¤ºï¼Œå³è¾¹æ”¾ç½®â€œæ¸…ç©ºæ•°æ®åº“â€æŒ‰é’®ã€‚ä¸»è¾“å…¥æ¡†ï¼š`st.text_input("è¯·è¾“å…¥é—®é¢˜")` åªæœ‰å½“æ•°æ®åº“å­˜åœ¨æ—¶æ‰èƒ½æé—®ã€‚    
ä¾§è¾¹æ ï¼š PDF ä¸Šä¼ å™¨ï¼›æäº¤æŒ‰é’®ï¼ˆå¤„ç†ä¸Šä¼ çš„ PDF â†’ åˆ†ç‰‡ â†’ å‘é‡åŒ– â†’ å­˜å‚¨ï¼‰ã€‚
æäº¤PDFåæ‰§è¡Œçš„é€»è¾‘ï¼šif process_button:- å½“ç‚¹å‡»â€œæäº¤å¹¶å¤„ç†â€åï¼š
è¯»å–ä¸Šä¼ çš„ PDFï¼› åˆ‡ç‰‡æ–‡æœ¬ï¼›å‘é‡åŒ–å…¥åº“ï¼›å¼¹å‡ºæ°”çƒæç¤ºï¼Œå¹¶ `st.rerun()` åˆ·æ–°é¡µé¢çŠ¶æ€ã€‚
##### LangChain RAGæ ¸å¿ƒåŠŸèƒ½ï¼š
- ä½¿ç”¨ `st.file_uploader()` ç»„ä»¶æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼Œå¹¶é€šè¿‡ `PyPDF2.PdfReader` å¯¹æ¯é¡µå†…å®¹è¿›è¡Œæå–ï¼Œç»„åˆä¸ºæ•´ä½“æ–‡æœ¬ã€‚
- ä½¿ç”¨ `RecursiveCharacterTextSplitter` å°†é•¿æ–‡æ¡£åˆ‡å‰²ä¸ºå›ºå®šé•¿åº¦ï¼ˆ1000å­—ï¼‰+ é‡å ï¼ˆ200å­—ï¼‰çš„å°å—ï¼Œå°†æ–‡æœ¬å—é€šè¿‡ `DashScopeEmbeddings` åµŒå…¥ä¸ºå‘é‡ï¼Œä½¿ç”¨ `FAISS` æœ¬åœ°å­˜å‚¨å‘é‡æ•°æ®åº“ã€‚
- é€šè¿‡ `Streamlit` è·å–ç”¨æˆ·è¾“å…¥é—®é¢˜ï¼Œå¦‚æœå‘é‡æ•°æ®åº“å­˜åœ¨ï¼Œåˆ™åŠ è½½ `FAISS` æ£€ç´¢å™¨ï¼Œä½¿ç”¨ `create_retriever_tool()` æ„å»º `LangChain` å·¥å…·ï¼Œäº¤ç”± `AgentExecutor` æ‰§è¡Œï¼Œè‡ªåŠ¨è°ƒç”¨æ£€ç´¢å™¨å¹¶ç”Ÿæˆç­”æ¡ˆã€‚
è¿è¡Œå‘½ä»¤ï¼šstreamlit run d:/LangChainlianxi/12rag.py
è‹¥æ˜¯æ²¡æœ‰å‡ºç°åœ°å€ï¼Œå¯ä»¥æŒ‰enteré”®
![[Pasted image 20250703120357.png]]
FAISSè¯å‘é‡çŸ¥è¯†åº“ç”¨æ¥å­˜å‚¨é•¿æ–‡æ¡£åˆ‡æˆçŸ­æ–‡æ¡£çš„æœ€ç»ˆç»“æœ
retrieveræ˜¯å¯ä»¥æŠŠragç³»ç»Ÿé‡Œé¢æ£€ç´¢éƒ¨åˆ†çš„åŠŸèƒ½å°è£…æˆå·¥å…·ï¼Œè¿™ä¸ªå·¥å…·å°±å¯ä»¥æ”¾åˆ°agenté‡Œé¢
```Python
    import streamlit as st
    from PyPDF2 import PdfReader
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_community.vectorstores import FAISS
    from langchain.tools.retriever import create_retriever_tool
    from langchain.agents import AgentExecutor, create_tool_calling_agent
    from langchain_community.embeddings import DashScopeEmbeddings
    from langchain.chat_models import init_chat_model
    import os
    from dotenv import load_dotenv 
    load_dotenv(override=True)


    DeepSeek_API_KEY = os.getenv("DEEPSEEK_API_KEY")
    dashscope_api_key = os.getenv("dashscope_api_key")

    os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"


    embeddings = DashScopeEmbeddings(
        model="text-embedding-v1", dashscope_api_key=dashscope_api_key
    )

    def pdf_read(pdf_doc):
        text = ""
        for pdf in pdf_doc:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                text += page.extract_text()
        return text


    def get_chunks(text):
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text(text)
        return chunks

    def vector_store(text_chunks):
        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
        vector_store.save_local("faiss_db")

    def get_conversational_chain(tools, ques):
        llm = init_chat_model("deepseek-chat", model_provider="deepseek")
        prompt = ChatPromptTemplate.from_messages([
            (
                "system",
                """ä½ æ˜¯AIåŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼Œç¡®ä¿æä¾›æ‰€æœ‰ç»†èŠ‚ï¼Œå¦‚æœç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œè¯·è¯´"ç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­"ï¼Œä¸è¦æä¾›é”™è¯¯çš„ç­”æ¡ˆ""",
            ),
            ("placeholder", "{chat_history}"),
            ("human", "{input}"),
            ("placeholder", "{agent_scratchpad}"),
        ])
        
        tool = [tools]
        agent = create_tool_calling_agent(llm, tool, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tool, verbose=True)
        
        response = agent_executor.invoke({"input": ques})
        print(response)
        st.write("ğŸ¤– å›ç­”: ", response['output'])

    def check_database_exists():
        """æ£€æŸ¥FAISSæ•°æ®åº“æ˜¯å¦å­˜åœ¨"""
        return os.path.exists("faiss_db") and os.path.exists("faiss_db/index.faiss")

    def user_input(user_question):
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        if not check_database_exists():
            st.error("âŒ è¯·å…ˆä¸Šä¼ PDFæ–‡ä»¶å¹¶ç‚¹å‡»'Submit & Process'æŒ‰é’®æ¥å¤„ç†æ–‡æ¡£ï¼")
            st.info("ğŸ’¡ æ­¥éª¤ï¼š1ï¸âƒ£ ä¸Šä¼ PDF â†’ 2ï¸âƒ£ ç‚¹å‡»å¤„ç† â†’ 3ï¸âƒ£ å¼€å§‹æé—®")
            return
        
        try:
            # åŠ è½½FAISSæ•°æ®åº“
            new_db = FAISS.load_local("faiss_db", embeddings, allow_dangerous_deserialization=True)
            
            retriever = new_db.as_retriever()
            retrieval_chain = create_retriever_tool(retriever, "pdf_extractor", "This tool is to give answer to queries from the pdf")
            get_conversational_chain(retrieval_chain, user_question)
            
        except Exception as e:
            st.error(f"âŒ åŠ è½½æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
            st.info("è¯·é‡æ–°å¤„ç†PDFæ–‡ä»¶")

    def main():
        st.set_page_config("ğŸ¤– LangChain Bç«™å…¬å¼€è¯¾ Byä¹å¤©Hector")
        st.header("ğŸ¤– LangChain Bç«™å…¬å¼€è¯¾ Byä¹å¤©Hector")
        
        # æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if check_database_exists():
            pass
            else:
                st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†PDFæ–‡ä»¶")
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®åº“"):
                try:
                    import shutil
                    if os.path.exists("faiss_db"):
                        shutil.rmtree("faiss_db")
                    st.success("æ•°æ®åº“å·²æ¸…é™¤")
                    st.rerun()
                except Exception as e:
                    st.error(f"æ¸…é™¤å¤±è´¥: {e}")

        # ç”¨æˆ·é—®é¢˜è¾“å…¥
        user_question = st.text_input("ğŸ’¬ è¯·è¾“å…¥é—®é¢˜", 
                                    placeholder="ä¾‹å¦‚ï¼šè¿™ä¸ªæ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                                    disabled=not check_database_exists())

        if user_question:
            if check_database_exists():
                with st.spinner("ğŸ¤” AIæ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    user_input(user_question)
            else:
                st.error("âŒ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†PDFæ–‡ä»¶ï¼")

        # ä¾§è¾¹æ 
        with st.sidebar:
            st.title("ğŸ“ æ–‡æ¡£ç®¡ç†")
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            if check_database_exists():
                st.success("âœ… æ•°æ®åº“çŠ¶æ€ï¼šå·²å°±ç»ª")
            else:
                st.info("ğŸ“ çŠ¶æ€ï¼šç­‰å¾…ä¸Šä¼ PDF")
            
            st.markdown("---")
            
            # æ–‡ä»¶ä¸Šä¼ 
            pdf_doc = st.file_uploader(
                "ğŸ“ ä¸Šä¼ PDFæ–‡ä»¶", 
                accept_multiple_files=True,
                type=['pdf'],
                help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶"
            )
            
            if pdf_doc:
                st.info(f"ğŸ“„ å·²é€‰æ‹© {len(pdf_doc)} ä¸ªæ–‡ä»¶")
                for i, pdf in enumerate(pdf_doc, 1):
                    st.write(f"{i}. {pdf.name}")
            
            # å¤„ç†æŒ‰é’®
            process_button = st.button(
                "ğŸš€ æäº¤å¹¶å¤„ç†", 
                disabled=not pdf_doc,
                use_container_width=True
            )
            
            if process_button:
                if pdf_doc:
                    with st.spinner("ğŸ“Š æ­£åœ¨å¤„ç†PDFæ–‡ä»¶..."):
                        try:
                            # è¯»å–PDFå†…å®¹
                            raw_text = pdf_read(pdf_doc)
                            
                            if not raw_text.strip():
                                st.error("âŒ æ— æ³•ä»PDFä¸­æå–æ–‡æœ¬ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ")
                                return
                            
                            # åˆ†å‰²æ–‡æœ¬
                            text_chunks = get_chunks(raw_text)
                            st.info(f"ğŸ“ æ–‡æœ¬å·²åˆ†å‰²ä¸º {len(text_chunks)} ä¸ªç‰‡æ®µ")
                            
                            # åˆ›å»ºå‘é‡æ•°æ®åº“
                            vector_store(text_chunks)
                            
                            st.success("âœ… PDFå¤„ç†å®Œæˆï¼ç°åœ¨å¯ä»¥å¼€å§‹æé—®äº†")
                            st.balloons()
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†PDFæ—¶å‡ºé”™: {str(e)}")
                else:
                    st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©PDFæ–‡ä»¶")
            
            # ä½¿ç”¨è¯´æ˜
            with st.expander("ğŸ’¡ ä½¿ç”¨è¯´æ˜"):
                st.markdown("""
                **æ­¥éª¤ï¼š**
                1. ğŸ“ ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªPDFæ–‡ä»¶
                2. ğŸš€ ç‚¹å‡»"Submit & Process"å¤„ç†æ–‡æ¡£
                3. ğŸ’¬ åœ¨ä¸»é¡µé¢è¾“å…¥æ‚¨çš„é—®é¢˜
                4. ğŸ¤– AIå°†åŸºäºPDFå†…å®¹å›ç­”é—®é¢˜
                
                **æç¤ºï¼š**
                - æ”¯æŒå¤šä¸ªPDFæ–‡ä»¶åŒæ—¶ä¸Šä¼ 
                - å¤„ç†å¤§æ–‡ä»¶å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
                - å¯ä»¥éšæ—¶æ¸…é™¤æ•°æ®åº“é‡æ–°å¼€å§‹
                """)

    if __name__ == "__main__":
        main()
```