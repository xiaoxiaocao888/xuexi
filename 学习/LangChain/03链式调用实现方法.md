##### 尝试搭建一个简单的链,将模型输出结果“过滤”为一个纯字符串格式
```Python
from langchain_core.output_parsers import StrOutputParser
from langchain.chat_models import init_chat_model

# 使用 DeepSeek 模型
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")  
# 直接使用模型 + 输出解析器搭建一个链
basic_qa_chain = model | StrOutputParser()
question = "你好，请你介绍一下你自己。" 
result = basic_qa_chain.invoke(question)
print(result)
```
![[Pasted image 20250701140312.png]]
此时result就不再是包含各种模型调用信息的结果，而是纯粹的模型响应的字符串结果。而这里用到的StrOutputParser()实际上就是用于构成LangChain中一个链条的一个对象，其核心功能是用于处理模型输出结果。同时我们也能发现，只需要使用`Model | OutputParser`，即可高效搭建一个链。

#####  加入提示词模板创建链
可以借助ChatPromptTemplate非常便捷的将一个提示词模板，同样以链的形式加入到当前任务中
```Python
from langchain.output_parsers.boolean import BooleanOutputParser
from langchain.prompts import ChatPromptTemplate
prompt_template = ChatPromptTemplate([
    ("system", "你是一个乐意助人的助手，请根据用户的问题给出回答"),
    ("user", "这是用户的问题： {topic}， 请用 yes 或 no 来回答")
])
# 直接使用模型 + 输出解析器
bool_qa_chain = prompt_template | model | StrOutputParser()
#bool_qa_chain = prompt_template | model | BooleanOutputParser() #输出变为False，就是将模型的输出修改为布尔类型。一般搭配有提示词，输出是no/yes/0/1
# 测试
question = "请问 1 + 1 是否 大于 2？"
result = bool_qa_chain.invoke(question)
print(result)
```
![[Pasted image 20250701140750.png]]

一个最基本的`Chain`结构，是由`Model`和`OutputParser`两个组件构成的，其中`Model`是用来调用大模型的，`OutputParser`是用来解析大模型的响应结果的。所以一个最简单的`LLMChain`结构，其数据流向正如下图所示：
![[Pasted image 20250701140838.png]]
当我们调用指令跟随能力较强的大模型的时候，借助提示词模板即可实现结构化输出的结果。

##### 借助提示词模板和结果解析器实现功能更加复杂的链
在LangChain中，一个基础的链主要由三部分构成，分别是提示词模板、大模型和结果解析器（结构化解析器）

核心的结构化解析器有

| 解析器名称                           | 功能描述                     | 类型     |
| ------------------------------- | ------------------------ | ------ |
| **BooleanOutputParser**         | 将LLM输出解析为布尔值             | 基础类型解析 |
| **DatetimeOutputParser**        | 将LLM输出解析为日期时间            | 基础类型解析 |
| **EnumOutputParser**            | 解析输出为预定义枚举值之一            | 基础类型解析 |
| **RegexParser**                 | 使用正则表达式解析LLM输出           | 模式匹配解析 |
| **RegexDictParser**             | 使用正则表达式将输出解析为字典          | 模式匹配解析 |
| **StructuredOutputParser**      | 将LLM输出解析为结构化格式           | 结构化解析  |
| **YamlOutputParser**            | 使用Pydantic模型解析YAML输出     | 结构化解析  |
| **PandasDataFrameOutputParser** | 使用Pandas DataFrame格式解析输出 | 数据处理解析 |
| **CombiningOutputParser**       | 将多个输出解析器组合为一个            | 组合解析器  |
| **OutputFixingParser**          | 包装解析器并尝试修复解析错误           | 错误处理解析 |
| **RetryOutputParser**           | 包装解析器并尝试修复解析错误           | 错误处理解析 |
| **RetryWithErrorOutputParser**  | 包装解析器并尝试修复解析错误           | 错误处理解析 |
| **ResponseSchema**              | 结构化输出解析器的响应模式            | 辅助类    |
StructuredOutputParser则可以在文档中提取指定的结构化信息
```Python
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_core.prompts import PromptTemplate
schemas = [
    ResponseSchema(name="name", description="用户的姓名"),
    ResponseSchema(name="age", description="用户的年龄")
]
parser = StructuredOutputParser.from_response_schemas(schemas)
prompt = PromptTemplate.from_template(
    "请根据以下内容提取用户信息，并返回 JSON 格式：\n{input}\n\n{format_instructions}"
)
chain = (
    prompt.partial(format_instructions=parser.get_format_instructions())
    | model
    | parser
)
result = chain.invoke({"input": "用户叫李雷，今年25岁，是一名工程师。"})
print(result)  
print(parser.get_format_instructions())
```
![[Pasted image 20250701142001.png]]
我们在 PromptTemplate 中，你定义了两个占位符变量：
- {input} → 将由用户传入的文本替换（如 "用户叫李雷，今年25岁..."）
- {format_instructions} → 会通过 partial(...) 提前绑定结构化格式说明

##### 创建复合链
```Python
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
# 第一步：根据标题生成新闻正文
news_gen_prompt = PromptTemplate.from_template(
    "请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\n\n标题：{title}"
)
# 第一个子链：生成新闻内容
news_chain = news_gen_prompt | model
# 第二步：从正文中提取结构化字段
schemas = [
    ResponseSchema(name="time", description="事件发生的时间"),
    ResponseSchema(name="location", description="事件发生的地点"),
    ResponseSchema(name="event", description="发生的具体事件"),
]
parser = StructuredOutputParser.from_response_schemas(schemas)
summary_prompt = PromptTemplate.from_template(
    "请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\n\n{news}\n\n{format_instructions}"
)
# 第二个子链：生成新闻摘要
summary_chain = (
summary_prompt.partial(format_instructions=parser.get_format_instructions())
    | model
    | parser
)
# 组合成一个复合 Chain
full_chain = news_chain | summary_chain
from langchain_core.runnables import RunnableLambda
# 一个简单的打印函数，调试用
def debug_print(x):
    print("中间结果（新闻正文）:", x)
    return x

debug_node = RunnableLambda(debug_print) #封装成LangChain可以识别的节点

# 插入 debug 节点
full_chain2 = news_chain | debug_node | summary_chain
# 调用复合链
result = full_chain.invoke({"title": "苹果公司在加州发布新款AI芯片"})
result2 = full_chain2.invoke({"title": "苹果公司在加州发布新款AI芯片"})
print(result)
print(result2)
```
![[Pasted image 20250701143202.png]]
1. `ChatPromptTemplate` 是用来构建提示模板的，将输入的问题转化为消息列表，可以设置系统指令，也可以添加一些变量；
2. `Model` 是用来调用大模型的，可以指定使用不同的模型；
3. `OutputParser` 是用来解析大模型的响应结果的，可以指定使用不同的解析器。
串联运行的
![[Pasted image 20250701150150.png]]