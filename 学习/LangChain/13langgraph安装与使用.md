```bash
pip install langgraph -i https://pypi.tuna.tsinghua.edu.cn/simple
pip show langgraph
pip install python-dotenv openai
pip install langchain-deepseek
```
è¿™é‡Œä¸€æ ·è¦åœ¨.envæ–‡ä»¶å†™å…¥DEEPSEEK_API_KEY

åœ¨langgraphä¸­ï¼Œæ˜¯é€šè¿‡ä¸€ä¸ª`ç»“æ„åŒ–å·¥å…·å‡½æ•°`æ¥è¯´æ˜å¤–éƒ¨å‡½æ•°çš„å‚æ•°è¾“å…¥ï¼ˆåŒ…æ‹¬å‚æ•°ç±»å‹ï¼‰ï¼Œä»¥ç¡®ä¿åœ¨å®é™…è°ƒç”¨è¿‡ç¨‹ä¸­å¤§æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å¤–éƒ¨å‡½æ•°çš„å‚æ•°ç±»å‹åŠå…¶å®é™…å«ä¹‰

å…¶ä¸­Pydantic æä¾›çš„ BaseModel è´Ÿè´£å®šä¹‰å¤–éƒ¨å‡½æ•°çš„å‚æ•°ç»“æ„ï¼Œç›¸å½“äºæ˜¯å‘Šè¯‰æ¨¡å‹å¤–éƒ¨å‡½æ•°å‚æ•°åæ˜¯ cityã€ç±»å‹æ˜¯å­—ç¬¦ä¸²ï¼ˆstrï¼‰ã€æè¿°ä¸ºâ€œåŸå¸‚åç§°â€ï¼Œæœ‰äº†è¿™ä¸ªç»“æ„ï¼Œæ¨¡å‹èƒ½æ›´å¥½åœ°ç†è§£å¦‚ä½•è°ƒç”¨è¯¥å‡½æ•°ã€‚
```python
from langchain_core.tools import tool 
from pydantic import BaseModel, Field 
class WeatherQuery(BaseModel): 
       city: str = Field(description="The location name of the city") @tool(args_schema = WeatherQuery)
def fetch_weather(city: str) -> dict[str, Any] | None:
```
å¦‚æœæ˜¯å°†å¤–éƒ¨å·¥å…·æ¥å…¥OpenAI Agents SDK
```python
from agents import function_tool 
@function_tool 
def get_weather(loc):
```
åˆ›å»ºLangGraphæ™ºèƒ½ä½“
```python
tools = [fetch_weather]
from langgraph.prebuilt import create_react_agent
from langchain.chat_models import init_chat_model
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")  
agent = create_react_agent(model=model, tools=tools)
response = agent.invoke({"messages": [{"role": "user", "content": "è¯·é—®åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"}]})
print(response["messages"][-1].content)
```
å€ŸåŠ©LangGraph React Agentï¼Œæ— éœ€ä»»ä½•é¢å¤–è®¾ç½®ï¼Œå³å¯å®Œæˆå¤šå·¥å…·ä¸²è”å’Œå¹¶è”è°ƒç”¨ã€‚

 LangChainå·¥å…·é›†ï¼š https://python.langchain.com/docs/integrations/tools/
ä¸»è¦çš„å†…ç½®å·¥å…·æœ‰

|   |   |   |
|---|---|---|
|åŠŸèƒ½ç±»åˆ«|å·¥å…·åç§°|ç®€è¦è¯´æ˜|
|ğŸ” æœç´¢å·¥å…·|`TavilySearchResults`|å¿«é€Ÿæœç´¢å®æ—¶ç½‘ç»œä¿¡æ¯|
||`SerpAPIWrapper`|åŸºäº SerpAPI çš„æœç´¢ç»“æœå·¥å…·|
||`GoogleSearchAPIWrapper`|è°ƒç”¨ Google å¯ç¼–ç¨‹æœç´¢å¼•æ“|
|ğŸ§  è®¡ç®—å·¥å…·|`PythonREPLTool`|æ‰§è¡Œ Python è¡¨è¾¾å¼å¹¶è¿”å›ç»“æœ|
||`LLMMathTool`|ç»“åˆ LLM å’Œæ•°å­¦æ¨ç†èƒ½åŠ›|
||`WolframAlphaQueryRun`|åŸºäº Wolfram Alpha çš„è®¡ç®—å¼•æ“|
|ğŸ—‚ æ•°æ®å·¥å…·|`SQLDatabaseToolkit`|æ„å»º SQL æ•°æ®åº“æŸ¥è¯¢å·¥å…·é›†|
||`PandasDataframeTool`|ç”¨äºåœ¨ Agent ä¸­æ“ä½œè¡¨æ ¼æ•°æ®|
|ğŸŒ ç½‘ç»œ/API|`RequestsGetTool` / `RequestsPostTool`|æ‰§è¡Œ HTTP è¯·æ±‚|
||`BrowserTool` / `PlaywrightBrowserToolkit`|è‡ªåŠ¨åŒ–ç½‘é¡µæµè§ˆä¸æŠ“å–|
|ğŸ’¾ æ–‡ä»¶å¤„ç†|`ReadFileTool`|è¯»å–æœ¬åœ°æ–‡ä»¶å†…å®¹|
||`WriteFileTool`|å†™å…¥æ–‡æœ¬åˆ°æŒ‡å®šæ–‡ä»¶ä¸­|
|ğŸ“š æ£€ç´¢å·¥å…·|`FAISSRetriever`|åŸºäºå‘é‡çš„æ–‡æ¡£æ£€ç´¢å·¥å…·|
||`ChromaRetriever`|ä½¿ç”¨ ChromaDB çš„æ£€ç´¢å™¨|
||`ContextualCompressionRetriever`|ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ï¼Œé€‚åˆé•¿æ–‡æ¡£|
|ğŸ§  LLM å·¥å…·|`ChatOpenAI` / `OpenAIFunctionsTool`|ä½¿ç”¨ OpenAI æ¨¡å‹ä½œä¸ºå·¥å…·è°ƒç”¨|
||`ChatAnthropic`|Anthropic Claude æ¨¡å‹å°è£…å·¥å…·|
|ğŸ”§ è‡ªå®šä¹‰å·¥å…·|`@tool` è£…é¥°å™¨|ä»»æ„å‡½æ•°å¯å°è£…ä¸º Agent å¯è°ƒç”¨å·¥å…·|
||`Tool` ç±»ç»§æ‰¿|è‡ªå®šä¹‰æ›´å¤æ‚é€»è¾‘çš„å·¥å…·å®ç°|
ä½¿ç”¨å†…ç½®å·¥å…·tavilyï¼Œå’Œ08ç¬”è®°ç±»ä¼¼ã€‚åŒºåˆ«æ˜¯ä½¿ç”¨langgraphçš„agentæ–¹æ³•
```python
import os
from dotenv import load_dotenv 
load_dotenv(override=True)
from langchain_tavily import TavilySearch
from langgraph.prebuilt import create_react_agent
from langchain.chat_models import init_chat_model
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")  
search = TavilySearch(max_results=5,topic="general")
tools = [search]
agent = create_react_agent(model=model, tools=tools)
response=agent.invoke({"messages": [{"role": "user", "content": "è¯·å¸®æˆ‘æœç´¢æœ€è¿‘OpenAI CEOåœ¨è®¿è°ˆä¸­çš„æ ¸å¿ƒè§‚ç‚¹ã€‚"}]})
print(response["messages"][-1].content)
```
![[Pasted image 20250710151815.png]]

**åœ¨Agentè¿è¡Œçš„æ—¶å€™è®¾ç½®{"recursion_limit": X}ï¼Œå³å¯é™åˆ¶æ™ºèƒ½ä½“è‡ªä¸»æ‰§è¡Œä»»åŠ¡æ—¶çš„æ­¥æ•°ã€‚**
xç­‰äº`len(response["messages"])`
```Python
try:
    response = agent.invoke(
        {"messages": [{"role": "user", "content": "è¯·é—®åŒ—äº¬ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ"}]},
        {"recursion_limit": 4},
    )
except GraphRecursionError:
    print("Agent stopped due to max iterations.")
```
é˜²æ­¢é™·å…¥æ­»å¾ªç¯ã€‚ä¸€èˆ¬æ˜¯4æ­¥ï¼Œæ¥å—ç”¨æˆ·æ¶ˆæ¯ï¼Œå‘èµ·function call messageï¼Œæ”¶åˆ°function response message,ç»™ç”¨æˆ·å‘é€final responseã€‚
**æ™ºèƒ½ä½“è®°å¿†ç®¡ç†ä¸å¤šè½®å¯¹è¯æ–¹æ³•**
ä¿å­˜çš„ä¸ä»…ä»…æ˜¯å†å²å¯¹è¯ï¼Œè¿˜å¯ä»¥æ˜¯å›¾ç»“æ„è¿è¡ŒçŠ¶æ€çš„ä¸€æ¬¡å¿«ç…§
ä½¿ç”¨ï¼šå¯¼å…¥åº“ï¼Œå®ä¾‹åŒ–ï¼Œåœ¨åˆ›å»ºæ™ºèƒ½ä½“æ—¶ï¼ŒåŠ å…¥checkpointer=å®ä¾‹åŒ–å¯¹è±¡ã€‚è¿˜è¦æœ‰çº¿ç¨‹ã€‚æ ¹æ®çº¿ç¨‹idåŒºåˆ†å¯¹è¯
```Python
from langgraph.checkpoint.memory import InMemorySaver
checkpointer = InMemorySaver()
tools = [fetch_weather]
model = init_chat_model(model="deepseek-chat", model_provider="deepseek")  
agent = create_react_agent(model=model, 
                           tools=tools,
                           checkpointer=checkpointer)
config = {
    "configurable": {
        "thread_id": "1"  
    }
}
response = agent.invoke(
    {"messages": [{"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘å«é™ˆæ˜ï¼Œå¥½ä¹…ä¸è§ï¼"}]},
    config
)
print(response['messages'])
#æ­¤æ—¶è®°å¿†è‡ªåŠ¨ä¿å­˜åœ¨å½“å‰Agentå’Œçº¿ç¨‹ä¸­
latest = agent.get_state(config)
print(latest)
#å½“æˆ‘ä»¬å†æ¬¡è¿›è¡Œå¯¹è¯æ—¶ï¼Œç›´æ¥å¸¦å…¥çº¿ç¨‹IDï¼Œå³å¯å¸¦å…¥æ­¤å‰å¯¹è¯è®°å¿†ï¼š
response1 = agent.invoke(
    {"messages": [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·é—®ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ"}]},
    config
)
print(response1['messages'])
latest = agent.get_state(config)
print(latest)
#å¦‚æœæ›´æ–°çº¿ç¨‹IDï¼Œåˆ™ä¼šé‡æ–°å¼€å¯å¯¹è¯
config2 = {
    "configurable": {
        "thread_id": "2"  
    }
}
response3 = agent.invoke(
    {"messages": [{"role": "user", "content": "ä½ å¥½ï¼Œä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ä¹ˆï¼Ÿ"}]},
    config2
)
print(response3['messages'])
```
![[Pasted image 20250710154756.png]]