##### pyspark-submit命令
```
/usr/local/spark/bin/spark-submit \
  --master local \
  --conf "spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/usr/local/spark/conf/log4j.properties" \
  --conf "spark.executor.extraJavaOptions=-Dlog4j.configuration=file:/usr/local/spark/conf/log4j.properties" \
  /usr/local/spark/mycode/remdup/remdup.py
```

##### 关于pyspark环境的一些命令
- 列出所有的conda 环境
```
conda env list
```
- 创建pyspark环境
```
conda create -n pyspark python=3.8
```
- 激活环境pyspark
```
conda activate pyspark
```
- 如果提示 "CommandNotFoundError"，需先初始化Conda
```
conda init bash #初始化conda到bash shell
source ~/.bashrc #重新加载配置
conda activate pyspark #重新激活
```
- 在某某环境下安装某某
```
conda install 下载的名字
```
- 进入某某环境，直接写环境名，如pyspark


进入spark shell 
pyspark