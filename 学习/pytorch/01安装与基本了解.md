CPU版本的PyTorch：主要依赖于计算机的中央处理器CPU。在处理规模较小的模型和数据集时表现良好。
GPU(CUDDA)版本的PyTorch：依赖于图像处理器GPU。可以充分利用GPU的并行计算能力，显著提高计算速度。只有自己电脑的GPU是英伟达的才可以。我的不是。可以去任务管理器性能那里看。
下载CPU版本的
```
pip3 install torch torchvision torchaudio
```
我们在tf1_env虚拟环境下已经安装过了。
PyTorch 是 Torch 的​**​现代化继承者​**​，由 Facebook（现 Meta）团队在 2017 年推出，​**​保留了 Torch 的核心计算引擎（如张量库）**
实际安装包名 `torch` 代表的是 PyTorch 框架的核心组件​，是python包，不是旧版的Lua Torch。

神经网络的层级结构通常包括输入层、隐藏层和输出层，每一层都由若干个神经元或称为节点组成。其中每个节点又被称为感知机模型。

**神经网络的pytorch API**:
```
torch.nn.Linear(in_features,out_features,bias=True,device=None,dtype=None)
```
输入的节点数，输出的节点数，是否启用偏置b(开始时随机初始化，然后随着网络的变化呢进行一个自我更新，若是false就恒为0)，电脑环境(GPU/CPU),计算的数据类型

如要进行图片检测，那么预测值和真实值会有一个距离，那么这个距离我们可以使用损失函数的方法来进行表示，如`0.5*(y-y1)**2=loss`，那么求距离的最小值问题就会转换为求损失函数的极小值，在深度学习里面我们是使用梯度下降算法来求极小值。
梯度的图像就是求导的图像，然后新参数w=旧参数w1-学习率lr×梯度g
通过不断的训练，我们得到的结果就会越来越接近。

**损失函数**
交叉熵损失函数：nn.CrossEntropyLoss()
平方差损失：nn.MSE()
**求导**
`loss.backward()`
**梯度下降：权重和偏置的更新**
`optimizer.step()`
